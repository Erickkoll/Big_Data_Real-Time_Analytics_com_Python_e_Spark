{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1vwR09lzuIt9"
   },
   "source": [
    "# <font color='blue'>Data Science Academy</font>\n",
    "# <font color='blue'>Big Data Real-Time Analytics com Python e Spark</font>\n",
    "\n",
    "## <font color='blue'>Mini-Projeto 4</font>\n",
    "\n",
    "### <font color='blue'>Data Science Aplicada em Logística com Spark SQL</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CT83d-fp2y6d"
   },
   "source": [
    "Leia os manuais em pdf no Capítulo 13 do curso com a definição do problema e a fonte de dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YkshydEd22VT",
    "outputId": "74a3d26d-f5cb-4748-91fe-ab9c066dab23"
   },
   "source": [
    "![title](imagens/MP4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versão da Linguagem Python Usada Neste Jupyter Notebook: 3.9.7\n"
     ]
    }
   ],
   "source": [
    "# Versão da Linguagem Python\n",
    "from platform import python_version\n",
    "print('Versão da Linguagem Python Usada Neste Jupyter Notebook:', python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para atualizar um pacote, execute o comando abaixo no terminal ou prompt de comando:\n",
    "# pip install -U nome_pacote\n",
    "\n",
    "# Para instalar a versão exata de um pacote, execute o comando abaixo no terminal ou prompt de comando:\n",
    "#!pip install nome_pacote==versão_desejada\n",
    "\n",
    "# Depois de instalar ou atualizar o pacote, reinicie o jupyter notebook.\n",
    "\n",
    "# Instala o pacote watermark. \n",
    "# Esse pacote é usado para gravar as versões de outros pacotes usados neste jupyter notebook.\n",
    "#!pip install -q -U watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa o findspark e inicializa\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import row_number\n",
    "from pyspark.sql.functions import lead  \n",
    "from pyspark.sql.functions import min, max\n",
    "from pyspark.sql.functions import unix_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Data Science Academy\n",
      "\n",
      "pyspark  : 3.3.0\n",
      "findspark: 2.0.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Versões dos pacotes usados neste jupyter notebook\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Data Science Academy\" --iversions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o Ambiente Spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/08/08 12:19:26 WARN Utils: Your hostname, falcon.local resolves to a loopback address: 127.0.0.1; using 10.0.0.87 instead (on interface en0)\n",
      "22/08/08 12:19:26 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/08/08 12:19:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Criando o Spark Context\n",
    "sc = SparkContext(appName = \"Mini-Projeto4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria a sessão\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h9QSWfrq2pNE",
    "outputId": "9fbf755d-de1f-4ed9-9dde-57ebefefe728"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.0.0.87:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Mini-Projeto4</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fb63fff3820>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TxthyP2Yvz3O"
   },
   "source": [
    "## Carregando os Dados Como Dataframe do Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "CL8KRjIquhmg"
   },
   "outputs": [],
   "source": [
    "# Nome do arquivo\n",
    "arquivo = 'dados/dataset.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega como dataframe do Spark\n",
    "# Não usaremos Pandas pois não vamos fazer análise exploratória de dados\n",
    "df = spark.read.csv(arquivo, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+\n",
      "|id_veiculo|  entrega|horario|\n",
      "+----------+---------+-------+\n",
      "|       298|Entrega 1|  7:58a|\n",
      "|       298|Entrega 2|  8:04a|\n",
      "|       298|Entrega 3|  8:17a|\n",
      "|       298|Entrega 4|  8:28a|\n",
      "|       298|Entrega 5|  8:33a|\n",
      "+----------+---------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J1P0HuTRuN2O"
   },
   "source": [
    "## Criando Tabela Temporária\n",
    "\n",
    "Criamos uma tabela temporária para executar consultas SQL nos dados. A tabela temporária existe somente nesta sessão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "RiTg59o2v-cT"
   },
   "outputs": [],
   "source": [
    "# Cria tabela temporária\n",
    "df.createOrReplaceTempView(\"tb_logistica\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fd-P7fEg4s5q"
   },
   "source": [
    "## Executando Queries SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|  col_name|\n",
      "+----------+\n",
      "|id_veiculo|\n",
      "|   entrega|\n",
      "|   horario|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verificando as colunas da tabela\n",
    "spark.sql(\"SHOW COLUMNS FROM tb_logistica\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+\n",
      "|id_veiculo|  entrega|horario|\n",
      "+----------+---------+-------+\n",
      "|       298|Entrega 1|  7:58a|\n",
      "|       298|Entrega 2|  8:04a|\n",
      "|       298|Entrega 3|  8:17a|\n",
      "|       298|Entrega 4|  8:28a|\n",
      "|       298|Entrega 5|  8:33a|\n",
      "+----------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Visualizando os 5 primeiros registros\n",
    "spark.sql(\"SELECT * FROM tb_logistica LIMIT 5\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C6ku5L374v08",
    "outputId": "70cfb37a-e9e3-4f67-8de8-4e59a4576d3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+\n",
      "|  col_name|data_type|comment|\n",
      "+----------+---------+-------+\n",
      "|id_veiculo|   string|   null|\n",
      "|   entrega|   string|   null|\n",
      "|   horario|   string|   null|\n",
      "+----------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Describe da tabela\n",
    "spark.sql(\"DESCRIBE tb_logistica\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Queries SQL x Dot Notation no Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+\n",
      "|veiculo|  entrega|\n",
      "+-------+---------+\n",
      "|    298|Entrega 1|\n",
      "|    298|Entrega 2|\n",
      "|    298|Entrega 3|\n",
      "|    298|Entrega 4|\n",
      "|    298|Entrega 5|\n",
      "+-------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query SQL\n",
    "spark.sql('SELECT id_veiculo AS veiculo, entrega FROM tb_logistica LIMIT 5').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+\n",
      "|veiculo|  entrega|\n",
      "+-------+---------+\n",
      "|    298|Entrega 1|\n",
      "|    298|Entrega 2|\n",
      "|    298|Entrega 3|\n",
      "|    298|Entrega 4|\n",
      "|    298|Entrega 5|\n",
      "+-------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dot Notation\n",
    "df.select(col('id_veiculo').alias('veiculo'), 'entrega').limit(5).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usando Funções SQL do Spark SQL\n",
    "\n",
    "Embora seja mais fácil usar direto Linguagem SQL, as funções do Spark SQL são otimizadas para o trabalho em ambiente distribuído. Se estiver com problemas de performance ao processar grandes conjuntos de dados, faça o teste com SQL e com o uso de funções e compare os resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id_veiculo: string, entrega: string, horario: string]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Após o nome do dataframe, digite . (ponto) e pressione a tecla tab para visualizar as funções (métodos) disponíveis\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id_veiculo', 'entrega', 'horario']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Colunas do dataframe\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos converter um Spark DataFrame para um Pandas DataFrame (e assim usar os métodos do Pandas)\n",
    "pandasDF = df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pandasDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id_veiculo    entrega horario\n",
      "0         298  Entrega 1   7:58a\n",
      "1         298  Entrega 2   8:04a\n",
      "2         298  Entrega 3   8:17a\n",
      "3         298  Entrega 4   8:28a\n",
      "4         298  Entrega 5   8:33a\n",
      "5         298  Entrega 6   8:39a\n",
      "6         298  Entrega 7   9:07a\n",
      "7         315  Entrega 1   6:05a\n",
      "8         315  Entrega 2   6:14a\n",
      "9         315  Entrega 3   6:24a\n",
      "10        315  Entrega 4   6:38a\n",
      "11        315  Entrega 5   6:45a\n",
      "12        315  Entrega 6   6:56a\n",
      "13        315  Entrega 7   7:32a\n",
      "14        457  Entrega 1   5:04a\n",
      "15        457  Entrega 2   5:13a\n",
      "16        457  Entrega 3   5:27a\n",
      "17        457  Entrega 4   5:39a\n",
      "18        457  Entrega 5   5:47a\n",
      "19        457  Entrega 6   6:21a\n",
      "20        457  Entrega 7   6:38a\n"
     ]
    }
   ],
   "source": [
    "print(pandasDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métodos Select e Collect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leia o manual em pdf no Capítulo 13 com as diferenças entre Select e Collect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Função select()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WUaLGlkHF7Qg",
    "outputId": "7e9d2bca-6ff8-4f59-e277-63c20191dfc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|id_veiculo|  entrega|\n",
      "+----------+---------+\n",
      "|       298|Entrega 1|\n",
      "|       298|Entrega 2|\n",
      "|       298|Entrega 3|\n",
      "|       298|Entrega 4|\n",
      "|       298|Entrega 5|\n",
      "|       298|Entrega 6|\n",
      "|       298|Entrega 7|\n",
      "|       315|Entrega 1|\n",
      "|       315|Entrega 2|\n",
      "|       315|Entrega 3|\n",
      "+----------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Selecionando dados de 2 colunas\n",
    "df.select('id_veiculo', 'entrega').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rB4fz07sGJ8Y",
    "outputId": "80c9538e-f842-416d-964c-b24373b73168"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|id_veiculo|  entrega|\n",
      "+----------+---------+\n",
      "|       298|Entrega 1|\n",
      "|       298|Entrega 2|\n",
      "|       298|Entrega 3|\n",
      "|       298|Entrega 4|\n",
      "|       298|Entrega 5|\n",
      "|       298|Entrega 6|\n",
      "|       298|Entrega 7|\n",
      "|       315|Entrega 1|\n",
      "|       315|Entrega 2|\n",
      "|       315|Entrega 3|\n",
      "+----------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Alternativamente podemos usar esta notação\n",
    "df.select(df.id_veiculo, df.entrega).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3XBZmdJ3GUyl",
    "outputId": "25fa37d6-e6be-4348-b9a4-8041bb9f61ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|id_veiculo|  entrega|\n",
      "+----------+---------+\n",
      "|       298|Entrega 1|\n",
      "|       298|Entrega 2|\n",
      "|       298|Entrega 3|\n",
      "|       298|Entrega 4|\n",
      "|       298|Entrega 5|\n",
      "|       298|Entrega 6|\n",
      "|       298|Entrega 7|\n",
      "|       315|Entrega 1|\n",
      "|       315|Entrega 2|\n",
      "|       315|Entrega 3|\n",
      "+----------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# A função col é outra alternativa\n",
    "from pyspark.sql.functions import col\n",
    "df.select(col('id_veiculo'), col('entrega')).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|id_veiculo|  entrega|\n",
      "+----------+---------+\n",
      "|       298|Entrega 1|\n",
      "|       298|Entrega 2|\n",
      "|       298|Entrega 3|\n",
      "|       298|Entrega 4|\n",
      "|       298|Entrega 5|\n",
      "|       298|Entrega 6|\n",
      "|       298|Entrega 7|\n",
      "|       315|Entrega 1|\n",
      "|       315|Entrega 2|\n",
      "|       315|Entrega 3|\n",
      "+----------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Podemos selecionar todas as colunas do dataframe cujos nomes estejam em uma lista\n",
    "nomes_colunas = [\"id_veiculo\", \"entrega\"]\n",
    "df.select(*nomes_colunas).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|id_veiculo|  entrega|\n",
      "+----------+---------+\n",
      "|       298|Entrega 1|\n",
      "|       298|Entrega 2|\n",
      "|       298|Entrega 3|\n",
      "|       298|Entrega 4|\n",
      "|       298|Entrega 5|\n",
      "|       298|Entrega 6|\n",
      "|       298|Entrega 7|\n",
      "|       315|Entrega 1|\n",
      "|       315|Entrega 2|\n",
      "|       315|Entrega 3|\n",
      "|       315|Entrega 4|\n",
      "|       315|Entrega 5|\n",
      "|       315|Entrega 6|\n",
      "|       315|Entrega 7|\n",
      "|       457|Entrega 1|\n",
      "|       457|Entrega 2|\n",
      "|       457|Entrega 3|\n",
      "|       457|Entrega 4|\n",
      "|       457|Entrega 5|\n",
      "|       457|Entrega 6|\n",
      "+----------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mesmo exemplo anterior mas agora com list comprehension\n",
    "df.select([coluna for coluna in nomes_colunas]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+\n",
      "|veiculo|  entrega|\n",
      "+-------+---------+\n",
      "|    298|Entrega 1|\n",
      "|    298|Entrega 2|\n",
      "|    298|Entrega 3|\n",
      "|    298|Entrega 4|\n",
      "|    298|Entrega 5|\n",
      "|    298|Entrega 6|\n",
      "|    298|Entrega 7|\n",
      "|    315|Entrega 1|\n",
      "|    315|Entrega 2|\n",
      "|    315|Entrega 3|\n",
      "+-------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Podemos renomear colunas para facilitar a consulta aos dados\n",
    "df.select('id_veiculo', 'entrega').withColumnRenamed('id_veiculo', 'veiculo').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+\n",
      "|veiculo|  entrega|\n",
      "+-------+---------+\n",
      "|    298|Entrega 1|\n",
      "|    298|Entrega 2|\n",
      "|    298|Entrega 3|\n",
      "|    298|Entrega 4|\n",
      "|    298|Entrega 5|\n",
      "|    298|Entrega 6|\n",
      "|    298|Entrega 7|\n",
      "|    315|Entrega 1|\n",
      "|    315|Entrega 2|\n",
      "|    315|Entrega 3|\n",
      "+-------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Também podemos usar um alias para renomear coluna\n",
    "df.select(col('id_veiculo').alias('veiculo'), 'entrega').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+\n",
      "|id_veiculo|  entrega|horario|\n",
      "+----------+---------+-------+\n",
      "|       298|Entrega 1|  7:58a|\n",
      "|       298|Entrega 2|  8:04a|\n",
      "|       298|Entrega 3|  8:17a|\n",
      "|       298|Entrega 4|  8:28a|\n",
      "|       298|Entrega 5|  8:33a|\n",
      "|       298|Entrega 6|  8:39a|\n",
      "|       298|Entrega 7|  9:07a|\n",
      "|       315|Entrega 1|  6:05a|\n",
      "|       315|Entrega 2|  6:14a|\n",
      "|       315|Entrega 3|  6:24a|\n",
      "|       315|Entrega 4|  6:38a|\n",
      "|       315|Entrega 5|  6:45a|\n",
      "|       315|Entrega 6|  6:56a|\n",
      "|       315|Entrega 7|  7:32a|\n",
      "|       457|Entrega 1|  5:04a|\n",
      "|       457|Entrega 2|  5:13a|\n",
      "|       457|Entrega 3|  5:27a|\n",
      "|       457|Entrega 4|  5:39a|\n",
      "|       457|Entrega 5|  5:47a|\n",
      "|       457|Entrega 6|  6:21a|\n",
      "+----------+---------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|horario|\n",
      "+-------+\n",
      "|  7:58a|\n",
      "|  8:04a|\n",
      "|  8:17a|\n",
      "+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Selecionando colunas pelo índice\n",
    "# A partir da coluna de índice 2 retorne as 3 primeiras linhas\n",
    "df.select(df.columns[2:]).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|  entrega|\n",
      "+---------+\n",
      "|Entrega 1|\n",
      "|Entrega 2|\n",
      "|Entrega 3|\n",
      "|Entrega 4|\n",
      "|Entrega 5|\n",
      "|Entrega 6|\n",
      "|Entrega 7|\n",
      "|Entrega 1|\n",
      "|Entrega 2|\n",
      "|Entrega 3|\n",
      "|Entrega 4|\n",
      "|Entrega 5|\n",
      "|Entrega 6|\n",
      "|Entrega 7|\n",
      "|Entrega 1|\n",
      "|Entrega 2|\n",
      "|Entrega 3|\n",
      "|Entrega 4|\n",
      "|Entrega 5|\n",
      "|Entrega 6|\n",
      "+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Selecionando colunas através de expressões regulares\n",
    "# https://docs.python.org/3.9/library/re.html\n",
    "df.select(df.colRegex(\"`^.*Entrega*`\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+\n",
      "|id_veiculo|  entrega|horario|\n",
      "+----------+---------+-------+\n",
      "|       298|Entrega 1|  7:58a|\n",
      "|       298|Entrega 2|  8:04a|\n",
      "|       298|Entrega 3|  8:17a|\n",
      "|       298|Entrega 4|  8:28a|\n",
      "|       298|Entrega 5|  8:33a|\n",
      "|       298|Entrega 6|  8:39a|\n",
      "|       298|Entrega 7|  9:07a|\n",
      "|       315|Entrega 1|  6:05a|\n",
      "|       315|Entrega 2|  6:14a|\n",
      "|       315|Entrega 3|  6:24a|\n",
      "|       315|Entrega 4|  6:38a|\n",
      "|       315|Entrega 5|  6:45a|\n",
      "|       315|Entrega 6|  6:56a|\n",
      "|       315|Entrega 7|  7:32a|\n",
      "|       457|Entrega 1|  5:04a|\n",
      "|       457|Entrega 2|  5:13a|\n",
      "|       457|Entrega 3|  5:27a|\n",
      "|       457|Entrega 4|  5:39a|\n",
      "|       457|Entrega 5|  5:47a|\n",
      "|       457|Entrega 6|  6:21a|\n",
      "|       457|Entrega 7|  6:38a|\n",
      "+----------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# O dataframe original segue intacto\n",
    "df.show(21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Vejamos agora a função collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id_veiculo='298', entrega='Entrega 1', horario='7:58a'),\n",
       " Row(id_veiculo='298', entrega='Entrega 2', horario='8:04a'),\n",
       " Row(id_veiculo='298', entrega='Entrega 3', horario='8:17a'),\n",
       " Row(id_veiculo='298', entrega='Entrega 4', horario='8:28a'),\n",
       " Row(id_veiculo='298', entrega='Entrega 5', horario='8:33a'),\n",
       " Row(id_veiculo='298', entrega='Entrega 6', horario='8:39a'),\n",
       " Row(id_veiculo='298', entrega='Entrega 7', horario='9:07a'),\n",
       " Row(id_veiculo='315', entrega='Entrega 1', horario='6:05a'),\n",
       " Row(id_veiculo='315', entrega='Entrega 2', horario='6:14a'),\n",
       " Row(id_veiculo='315', entrega='Entrega 3', horario='6:24a'),\n",
       " Row(id_veiculo='315', entrega='Entrega 4', horario='6:38a'),\n",
       " Row(id_veiculo='315', entrega='Entrega 5', horario='6:45a'),\n",
       " Row(id_veiculo='315', entrega='Entrega 6', horario='6:56a'),\n",
       " Row(id_veiculo='315', entrega='Entrega 7', horario='7:32a'),\n",
       " Row(id_veiculo='457', entrega='Entrega 1', horario='5:04a'),\n",
       " Row(id_veiculo='457', entrega='Entrega 2', horario='5:13a'),\n",
       " Row(id_veiculo='457', entrega='Entrega 3', horario='5:27a'),\n",
       " Row(id_veiculo='457', entrega='Entrega 4', horario='5:39a'),\n",
       " Row(id_veiculo='457', entrega='Entrega 5', horario='5:47a'),\n",
       " Row(id_veiculo='457', entrega='Entrega 6', horario='6:21a'),\n",
       " Row(id_veiculo='457', entrega='Entrega 7', horario='6:38a')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retornando cada linha do dataframe como um objeto do tipo Row\n",
    "df.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# O método collect() retorna uma lista de linhas\n",
    "new_df = df.collect()\n",
    "type(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7:58a'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Podemos \"fatiar\" as estruturas retornadas por collect()\n",
    "# Neste caso retornamos o elemento da primeira linha e terceira coluna\n",
    "df.collect()[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "298,Entrega 1\n",
      "298,Entrega 2\n",
      "298,Entrega 3\n",
      "298,Entrega 4\n",
      "298,Entrega 5\n",
      "298,Entrega 6\n",
      "298,Entrega 7\n",
      "315,Entrega 1\n",
      "315,Entrega 2\n",
      "315,Entrega 3\n",
      "315,Entrega 4\n",
      "315,Entrega 5\n",
      "315,Entrega 6\n",
      "315,Entrega 7\n",
      "457,Entrega 1\n",
      "457,Entrega 2\n",
      "457,Entrega 3\n",
      "457,Entrega 4\n",
      "457,Entrega 5\n",
      "457,Entrega 6\n",
      "457,Entrega 7\n"
     ]
    }
   ],
   "source": [
    "# Como collect() retorna uma lista, podemos percorrer a lista com um loop e concatenar as colunas, por exemplo\n",
    "for row in df.collect():\n",
    "    print(row['id_veiculo'] + \",\" + str(row['entrega']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id_veiculo='298'),\n",
       " Row(id_veiculo='298'),\n",
       " Row(id_veiculo='298'),\n",
       " Row(id_veiculo='298')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Podemos ainda combinar select e collect\n",
    "# Filtramos colunas com select e filtramos linhas com collect\n",
    "dataCollect = df.select(\"id_veiculo\").collect()[0:4][:]\n",
    "dataCollect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id_veiculo='298', entrega='Entrega 4', horario='8:28a'),\n",
       " Row(id_veiculo='298', entrega='Entrega 6', horario='8:39a'),\n",
       " Row(id_veiculo='298', entrega='Entrega 7', horario='9:07a'),\n",
       " Row(id_veiculo='315', entrega='Entrega 1', horario='6:05a'),\n",
       " Row(id_veiculo='315', entrega='Entrega 3', horario='6:24a'),\n",
       " Row(id_veiculo='315', entrega='Entrega 4', horario='6:38a'),\n",
       " Row(id_veiculo='457', entrega='Entrega 4', horario='5:39a'),\n",
       " Row(id_veiculo='457', entrega='Entrega 5', horario='5:47a'),\n",
       " Row(id_veiculo='457', entrega='Entrega 6', horario='6:21a'),\n",
       " Row(id_veiculo='457', entrega='Entrega 7', horario='6:38a')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Podemos extrair primeiro uma amostra do dataframe e então coletar o resultado\n",
    "df.sample(0.6).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métodos Filter e Where"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leia o manual em pdf no Capítulo 13 com a definição das funções Filter e Where."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+\n",
      "|id_veiculo|  entrega|horario|\n",
      "+----------+---------+-------+\n",
      "|       298|Entrega 2|  8:04a|\n",
      "|       315|Entrega 2|  6:14a|\n",
      "|       457|Entrega 2|  5:13a|\n",
      "+----------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Podemos filtrar os dados retornados com a função filter()\n",
    "df.filter(\"entrega == 'Entrega 2'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+\n",
      "|id_veiculo|  entrega|horario|\n",
      "+----------+---------+-------+\n",
      "|       298|Entrega 1|  7:58a|\n",
      "|       298|Entrega 3|  8:17a|\n",
      "|       298|Entrega 4|  8:28a|\n",
      "|       298|Entrega 5|  8:33a|\n",
      "|       298|Entrega 6|  8:39a|\n",
      "|       298|Entrega 7|  9:07a|\n",
      "|       315|Entrega 1|  6:05a|\n",
      "|       315|Entrega 3|  6:24a|\n",
      "|       315|Entrega 4|  6:38a|\n",
      "|       315|Entrega 5|  6:45a|\n",
      "|       315|Entrega 6|  6:56a|\n",
      "|       315|Entrega 7|  7:32a|\n",
      "|       457|Entrega 1|  5:04a|\n",
      "|       457|Entrega 3|  5:27a|\n",
      "|       457|Entrega 4|  5:39a|\n",
      "|       457|Entrega 5|  5:47a|\n",
      "|       457|Entrega 6|  6:21a|\n",
      "|       457|Entrega 7|  6:38a|\n",
      "+----------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Podemos filtrar os dados retornados com a função filter() usando a negação\n",
    "df.filter(\"entrega != 'Entrega 2'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+\n",
      "|id_veiculo|  entrega|horario|\n",
      "+----------+---------+-------+\n",
      "|       298|Entrega 2|  8:04a|\n",
      "+----------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Podemos filtrar usando múltiplas condições\n",
    "df.filter((df.entrega == \"Entrega 2\") & (df.id_veiculo == 298)).show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+\n",
      "|id_veiculo|  entrega|horario|\n",
      "+----------+---------+-------+\n",
      "|       298|Entrega 1|  7:58a|\n",
      "|       298|Entrega 2|  8:04a|\n",
      "|       298|Entrega 3|  8:17a|\n",
      "|       298|Entrega 4|  8:28a|\n",
      "|       298|Entrega 5|  8:33a|\n",
      "|       298|Entrega 6|  8:39a|\n",
      "|       298|Entrega 7|  9:07a|\n",
      "+----------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filtro baseado em lista\n",
    "lista_id_veiculos = [298, 300, 400]\n",
    "df.filter(df.id_veiculo.isin(lista_id_veiculos)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+\n",
      "|id_veiculo|  entrega|horario|\n",
      "+----------+---------+-------+\n",
      "|       315|Entrega 4|  6:38a|\n",
      "|       457|Entrega 7|  6:38a|\n",
      "+----------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Alguma entrega ocorreu no minuto 38 de qualquer hora?\n",
    "df.filter(df.horario.like(\"%38%\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+\n",
      "|id_veiculo|  entrega|horario|\n",
      "+----------+---------+-------+\n",
      "|       298|Entrega 2|  8:04a|\n",
      "|       315|Entrega 2|  6:14a|\n",
      "|       457|Entrega 2|  5:13a|\n",
      "+----------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Podemos filtrar os dados retornados com a função where()\n",
    "df.where(\"entrega == 'Entrega 2'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+\n",
      "|id_veiculo|  entrega|horario|\n",
      "+----------+---------+-------+\n",
      "|       457|Entrega 1|  5:04a|\n",
      "|       457|Entrega 2|  5:13a|\n",
      "|       457|Entrega 3|  5:27a|\n",
      "|       457|Entrega 4|  5:39a|\n",
      "|       457|Entrega 5|  5:47a|\n",
      "|       457|Entrega 6|  6:21a|\n",
      "|       457|Entrega 7|  6:38a|\n",
      "+----------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Podemos filtrar os dados retornados com a função where()\n",
    "df.where(\"id_veiculo > 400\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+\n",
      "|id_veiculo|  entrega|horario|\n",
      "+----------+---------+-------+\n",
      "|       298|Entrega 1|  7:58a|\n",
      "|       298|Entrega 2|  8:04a|\n",
      "|       298|Entrega 3|  8:17a|\n",
      "|       298|Entrega 4|  8:28a|\n",
      "|       298|Entrega 5|  8:33a|\n",
      "|       298|Entrega 6|  8:39a|\n",
      "|       298|Entrega 7|  9:07a|\n",
      "+----------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Where baseado em lista\n",
    "lista_id_veiculos = [298, 300, 400]\n",
    "df.where(df.id_veiculo.isin(lista_id_veiculos)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métodos Order By e Sort\n",
    "\n",
    "Leia o manual em pdf no Capítulo 13 com a definição das funções Order By e Sort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+\n",
      "|id_veiculo|  entrega|horario|\n",
      "+----------+---------+-------+\n",
      "|       457|Entrega 1|  5:04a|\n",
      "|       457|Entrega 2|  5:13a|\n",
      "|       457|Entrega 3|  5:27a|\n",
      "|       457|Entrega 4|  5:39a|\n",
      "|       457|Entrega 5|  5:47a|\n",
      "|       315|Entrega 1|  6:05a|\n",
      "|       315|Entrega 2|  6:14a|\n",
      "|       457|Entrega 6|  6:21a|\n",
      "|       315|Entrega 3|  6:24a|\n",
      "|       315|Entrega 4|  6:38a|\n",
      "+----------+---------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ordenando a seleção das linhas\n",
    "df.sort(\"horario\", \"entrega\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+\n",
      "|id_veiculo|  entrega|horario|\n",
      "+----------+---------+-------+\n",
      "|       457|Entrega 1|  5:04a|\n",
      "|       457|Entrega 2|  5:13a|\n",
      "|       457|Entrega 3|  5:27a|\n",
      "|       457|Entrega 4|  5:39a|\n",
      "|       457|Entrega 5|  5:47a|\n",
      "|       315|Entrega 1|  6:05a|\n",
      "|       315|Entrega 2|  6:14a|\n",
      "|       457|Entrega 6|  6:21a|\n",
      "|       315|Entrega 3|  6:24a|\n",
      "|       315|Entrega 4|  6:38a|\n",
      "+----------+---------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mesmo resultado anterior mas com a função col()\n",
    "df.sort(col(\"horario\"), col(\"entrega\")).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+\n",
      "|id_veiculo|  entrega|horario|\n",
      "+----------+---------+-------+\n",
      "|       457|Entrega 1|  5:04a|\n",
      "|       457|Entrega 2|  5:13a|\n",
      "|       457|Entrega 3|  5:27a|\n",
      "|       457|Entrega 4|  5:39a|\n",
      "|       457|Entrega 5|  5:47a|\n",
      "|       315|Entrega 1|  6:05a|\n",
      "|       315|Entrega 2|  6:14a|\n",
      "|       457|Entrega 6|  6:21a|\n",
      "|       315|Entrega 3|  6:24a|\n",
      "|       315|Entrega 4|  6:38a|\n",
      "|       457|Entrega 7|  6:38a|\n",
      "|       315|Entrega 5|  6:45a|\n",
      "|       315|Entrega 6|  6:56a|\n",
      "|       315|Entrega 7|  7:32a|\n",
      "|       298|Entrega 1|  7:58a|\n",
      "|       298|Entrega 2|  8:04a|\n",
      "|       298|Entrega 3|  8:17a|\n",
      "|       298|Entrega 4|  8:28a|\n",
      "|       298|Entrega 5|  8:33a|\n",
      "|       298|Entrega 6|  8:39a|\n",
      "+----------+---------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ou usamos Order By\n",
    "df.orderBy(col(\"horario\"), col(\"entrega\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+\n",
      "|id_veiculo|  entrega|horario|\n",
      "+----------+---------+-------+\n",
      "|       298|Entrega 7|  9:07a|\n",
      "|       298|Entrega 6|  8:39a|\n",
      "|       298|Entrega 5|  8:33a|\n",
      "|       298|Entrega 4|  8:28a|\n",
      "|       298|Entrega 3|  8:17a|\n",
      "|       298|Entrega 2|  8:04a|\n",
      "|       298|Entrega 1|  7:58a|\n",
      "|       315|Entrega 7|  7:32a|\n",
      "|       315|Entrega 6|  6:56a|\n",
      "|       315|Entrega 5|  6:45a|\n",
      "+----------+---------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ordena o resultado em ordem decrescente \n",
    "df.sort(df.horario.desc(), df.entrega.desc()).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+\n",
      "|id_veiculo|  entrega|horario|\n",
      "+----------+---------+-------+\n",
      "|       298|Entrega 7|  9:07a|\n",
      "|       298|Entrega 6|  8:39a|\n",
      "|       298|Entrega 5|  8:33a|\n",
      "|       298|Entrega 4|  8:28a|\n",
      "|       298|Entrega 3|  8:17a|\n",
      "|       298|Entrega 2|  8:04a|\n",
      "|       298|Entrega 1|  7:58a|\n",
      "|       315|Entrega 7|  7:32a|\n",
      "|       315|Entrega 6|  6:56a|\n",
      "|       315|Entrega 5|  6:45a|\n",
      "+----------+---------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lembre-se que podemos usar SQL\n",
    "spark.sql(\"select id_veiculo, entrega, horario from tb_logistica ORDER BY horario desc\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métodos Map, flatMap e Explode\n",
    "\n",
    "Leia o manual em pdf no Capítulo 13 com a definição das funções Map, flatMap e Explode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função map( ) em Python: https://docs.python.org/3.9/library/functions.html#map\n",
    "\n",
    "Função map( ) do Pandas: https://pandas.pydata.org/docs/reference/api/pandas.Series.map.html\n",
    "\n",
    "Função map( ) do Spark: https://spark.apache.org/docs/latest/api/sql/index.html#map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 36:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------+\n",
      "|      novo_id|entrega|\n",
      "+-------------+-------+\n",
      "|298,Entrega 1|  7:58a|\n",
      "|298,Entrega 2|  8:04a|\n",
      "|298,Entrega 3|  8:17a|\n",
      "|298,Entrega 4|  8:28a|\n",
      "|298,Entrega 5|  8:33a|\n",
      "|298,Entrega 6|  8:39a|\n",
      "|298,Entrega 7|  9:07a|\n",
      "|315,Entrega 1|  6:05a|\n",
      "|315,Entrega 2|  6:14a|\n",
      "|315,Entrega 3|  6:24a|\n",
      "|315,Entrega 4|  6:38a|\n",
      "|315,Entrega 5|  6:45a|\n",
      "|315,Entrega 6|  6:56a|\n",
      "|315,Entrega 7|  7:32a|\n",
      "|457,Entrega 1|  5:04a|\n",
      "|457,Entrega 2|  5:13a|\n",
      "|457,Entrega 3|  5:27a|\n",
      "|457,Entrega 4|  5:39a|\n",
      "|457,Entrega 5|  5:47a|\n",
      "|457,Entrega 6|  6:21a|\n",
      "+-------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Maps são aplicados em RDDs e por isso precisamos converter o dataframe para RDD\n",
    "# O método Map retorna um RDD e por isso temos que converter de volta para dataframe\n",
    "rdd2 = df.rdd.map(lambda x: (x[0] + \",\" + x[1], x[2]))  \n",
    "df2 = rdd2.toDF([\"novo_id\", \"entrega\"])\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id_veiculo', 'entrega', 'horario']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------+\n",
      "|      novo_id|entrega|\n",
      "+-------------+-------+\n",
      "|298,Entrega 1|  7:58a|\n",
      "|298,Entrega 2|  8:04a|\n",
      "|298,Entrega 3|  8:17a|\n",
      "|298,Entrega 4|  8:28a|\n",
      "|298,Entrega 5|  8:33a|\n",
      "|298,Entrega 6|  8:39a|\n",
      "|298,Entrega 7|  9:07a|\n",
      "|315,Entrega 1|  6:05a|\n",
      "|315,Entrega 2|  6:14a|\n",
      "|315,Entrega 3|  6:24a|\n",
      "|315,Entrega 4|  6:38a|\n",
      "|315,Entrega 5|  6:45a|\n",
      "|315,Entrega 6|  6:56a|\n",
      "|315,Entrega 7|  7:32a|\n",
      "|457,Entrega 1|  5:04a|\n",
      "|457,Entrega 2|  5:13a|\n",
      "|457,Entrega 3|  5:27a|\n",
      "|457,Entrega 4|  5:39a|\n",
      "|457,Entrega 5|  5:47a|\n",
      "|457,Entrega 6|  6:21a|\n",
      "+-------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mesmo exemplo anterior mas usando o nome da coluna e não o índice\n",
    "rdd2 = df.rdd.map(lambda x: (x['id_veiculo'] + \",\" + x['entrega'], x['horario']))  \n",
    "df2 = rdd2.toDF([\"novo_id\", \"entrega\"])\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criamos uma função que manipula as colunas\n",
    "def manipula_colunas(x):\n",
    "    coluna1 = x.id_veiculo\n",
    "    coluna2 = x.entrega\n",
    "    novo_id = coluna1 + \"-\" + coluna2\n",
    "    coluna3 = x.horario\n",
    "    return (novo_id, coluna3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usamos a função map para aplicar a função lambda (anônima), que aplica a função manipula_colunas a cada linha do RDD\n",
    "rdd2 = df.rdd.map(lambda x: manipula_colunas(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('298-Entrega 1', '7:58a'),\n",
       " ('298-Entrega 2', '8:04a'),\n",
       " ('298-Entrega 3', '8:17a'),\n",
       " ('298-Entrega 4', '8:28a'),\n",
       " ('298-Entrega 5', '8:33a'),\n",
       " ('298-Entrega 6', '8:39a'),\n",
       " ('298-Entrega 7', '9:07a'),\n",
       " ('315-Entrega 1', '6:05a'),\n",
       " ('315-Entrega 2', '6:14a'),\n",
       " ('315-Entrega 3', '6:24a'),\n",
       " ('315-Entrega 4', '6:38a'),\n",
       " ('315-Entrega 5', '6:45a'),\n",
       " ('315-Entrega 6', '6:56a'),\n",
       " ('315-Entrega 7', '7:32a'),\n",
       " ('457-Entrega 1', '5:04a'),\n",
       " ('457-Entrega 2', '5:13a'),\n",
       " ('457-Entrega 3', '5:27a'),\n",
       " ('457-Entrega 4', '5:39a'),\n",
       " ('457-Entrega 5', '5:47a'),\n",
       " ('457-Entrega 6', '6:21a'),\n",
       " ('457-Entrega 7', '6:38a')]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collect no RDD\n",
    "rdd2.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O método flatMap requer uma lista no formato RDD\n",
    "# Vamos criar uma lista\n",
    "data = [\"A Data Science Academy\",\n",
    "        \"oferece cursos realmente incríveis\",\n",
    "        \"orientados às necessidades\",\n",
    "        \"do mercado de trabalho\",\n",
    "        \"e tudo mostrado passo a passo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convertemos a lista em um RDD\n",
    "rdd = spark.sparkContext.parallelize(data)\n",
    "type(rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Data Science Academy\n",
      "oferece cursos realmente incríveis\n",
      "orientados às necessidades\n",
      "do mercado de trabalho\n",
      "e tudo mostrado passo a passo\n"
     ]
    }
   ],
   "source": [
    "# Imprime os elementos do RDD\n",
    "for element in rdd.collect():\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora aplicamos o flatMap, que cria outro RDD  \n",
    "rdd2 = rdd.flatMap(lambda x: x.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "Data\n",
      "Science\n",
      "Academy\n",
      "oferece\n",
      "cursos\n",
      "realmente\n",
      "incríveis\n",
      "orientados\n",
      "às\n",
      "necessidades\n",
      "do\n",
      "mercado\n",
      "de\n",
      "trabalho\n",
      "e\n",
      "tudo\n",
      "mostrado\n",
      "passo\n",
      "a\n",
      "passo\n"
     ]
    }
   ],
   "source": [
    "# Imprime os elementos do RDD\n",
    "for element in rdd2.collect():\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode deve receber uma lista como argumento, mas essa lista pode estar em uma coluna de um dataframe\n",
    "from pyspark.sql.functions import explode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria uma lista\n",
    "array_estudantes = [('Bob', ['Python', 'R', 'Scala']),\n",
    "                    ('Maria', ['Java','Julia']),\n",
    "                    ('Zico', ['JavaScript', '']),\n",
    "                    ('Ana', [None, None])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(array_estudantes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converte a lista para dataframe\n",
    "df_estudantes = spark.createDataFrame(data = array_estudantes, schema = ['aluno', 'linguagem'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_estudantes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- aluno: string (nullable = true)\n",
      " |-- col: string (nullable = true)\n",
      "\n",
      "+-----+----------+\n",
      "|aluno|       col|\n",
      "+-----+----------+\n",
      "|  Bob|    Python|\n",
      "|  Bob|         R|\n",
      "|  Bob|     Scala|\n",
      "|Maria|      Java|\n",
      "|Maria|     Julia|\n",
      "| Zico|JavaScript|\n",
      "| Zico|          |\n",
      "|  Ana|      null|\n",
      "|  Ana|      null|\n",
      "+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select com explode\n",
    "df2 = df_estudantes.select(df_estudantes.aluno, explode(df_estudantes.linguagem))\n",
    "df2.printSchema()\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id_veiculo', 'entrega', 'horario']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "298,Entrega 1,7:58a\n",
      "298,Entrega 2,8:04a\n",
      "298,Entrega 3,8:17a\n",
      "298,Entrega 4,8:28a\n",
      "298,Entrega 5,8:33a\n",
      "298,Entrega 6,8:39a\n",
      "298,Entrega 7,9:07a\n",
      "315,Entrega 1,6:05a\n",
      "315,Entrega 2,6:14a\n",
      "315,Entrega 3,6:24a\n",
      "315,Entrega 4,6:38a\n",
      "315,Entrega 5,6:45a\n",
      "315,Entrega 6,6:56a\n",
      "315,Entrega 7,7:32a\n",
      "457,Entrega 1,5:04a\n",
      "457,Entrega 2,5:13a\n",
      "457,Entrega 3,5:27a\n",
      "457,Entrega 4,5:39a\n",
      "457,Entrega 5,5:47a\n",
      "457,Entrega 6,6:21a\n",
      "457,Entrega 7,6:38a\n"
     ]
    }
   ],
   "source": [
    "# Foreach\n",
    "df.foreach(lambda x: print(x[\"id_veiculo\"] + \",\" + x[\"entrega\"] + \",\" + x[\"horario\"])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agregação com Spark SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Agregação com Funções do Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id_veiculo', 'entrega', 'horario']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|id_veiculo|count|\n",
      "+----------+-----+\n",
      "|       298|    7|\n",
      "|       457|    7|\n",
      "|       315|    7|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"id_veiculo\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A linha de código abaixo não funciona. LEIA A MENSAGEM DE ERRO!!!\n",
    "# df.groupBy(\"id_veiculo\").min(\"horario\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+\n",
      "|id_veiculo|min(horario)|\n",
      "+----------+------------+\n",
      "|       298|       7:58a|\n",
      "|       315|       6:05a|\n",
      "|       457|       5:04a|\n",
      "+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('id_veiculo').agg({'horario':'min'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+\n",
      "|id_veiculo|max(horario)|\n",
      "+----------+------------+\n",
      "|       298|       9:07a|\n",
      "|       315|       7:32a|\n",
      "|       457|       6:38a|\n",
      "+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('id_veiculo').agg({'horario':'max'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+\n",
      "|id_veiculo|count(horario)|\n",
      "+----------+--------------+\n",
      "|       298|             7|\n",
      "|       457|             7|\n",
      "|       315|             7|\n",
      "+----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('id_veiculo').agg({'horario':'count'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+\n",
      "|id_veiculo|numero_entregas|\n",
      "+----------+---------------+\n",
      "|       298|              7|\n",
      "|       457|              7|\n",
      "|       315|              7|\n",
      "+----------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('id_veiculo').agg({'horario':'count'}).withColumnRenamed('count(horario)', 'numero_entregas').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------------+\n",
      "|id_veiculo|hora_primeira_entrega|\n",
      "+----------+---------------------+\n",
      "|       298|                7:58a|\n",
      "|       315|                6:05a|\n",
      "|       457|                5:04a|\n",
      "+----------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('id_veiculo').agg({'horario':'min'}).withColumnRenamed('min(horario)', 'hora_primeira_entrega').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Agregação com Queries SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+\n",
      "|id_veiculo|numero_entregas|\n",
      "+----------+---------------+\n",
      "|       298|              7|\n",
      "|       457|              7|\n",
      "|       315|              7|\n",
      "+----------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Usando função SQL do SparkSQL\n",
    "df.groupBy(\"id_veiculo\").count().withColumnRenamed('count', 'numero_entregas').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a query\n",
    "# Número de entregas por id_veiculo\n",
    "query = \"\"\"\n",
    "SELECT id_veiculo, COUNT(*) AS numero_entregas\n",
    "FROM tb_logistica\n",
    "GROUP BY id_veiculo\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+\n",
      "|id_veiculo|numero_entregas|\n",
      "+----------+---------------+\n",
      "|       298|              7|\n",
      "|       457|              7|\n",
      "|       315|              7|\n",
      "+----------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Executa a query\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a query\n",
    "# Primeiro (menor) e último (maior) horário de entrega por id_veiculo\n",
    "query = \"\"\"\n",
    "SELECT id_veiculo, MIN(horario) AS hora_primeira_entrega, MAX(horario) AS hora_ultima_entrega\n",
    "FROM tb_logistica\n",
    "GROUP BY id_veiculo\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------------+-------------------+\n",
      "|id_veiculo|hora_primeira_entrega|hora_ultima_entrega|\n",
      "+----------+---------------------+-------------------+\n",
      "|       298|                7:58a|              9:07a|\n",
      "|       315|                6:05a|              7:32a|\n",
      "|       457|                5:04a|              6:38a|\n",
      "+----------+---------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Executa a query\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a query\n",
    "# Número de entregas por horário para o id_veiculo 298\n",
    "query = \"\"\"\n",
    "SELECT horario, COUNT(*) AS hora_ultima_entrega\n",
    "FROM tb_logistica\n",
    "WHERE id_veiculo = 298\n",
    "GROUP BY horario\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+\n",
      "|horario|hora_ultima_entrega|\n",
      "+-------+-------------------+\n",
      "|  8:33a|                  1|\n",
      "|  8:28a|                  1|\n",
      "|  8:17a|                  1|\n",
      "|  8:39a|                  1|\n",
      "|  8:04a|                  1|\n",
      "|  7:58a|                  1|\n",
      "|  9:07a|                  1|\n",
      "+-------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Executa a query\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a query\n",
    "# Número de entregas por horário\n",
    "query = \"\"\"\n",
    "SELECT horario, COUNT(*) AS numero_entregas\n",
    "FROM tb_logistica\n",
    "GROUP BY horario\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------+\n",
      "|horario|numero_entregas|\n",
      "+-------+---------------+\n",
      "|  8:33a|              1|\n",
      "|  6:45a|              1|\n",
      "|  8:28a|              1|\n",
      "|  5:39a|              1|\n",
      "|  8:17a|              1|\n",
      "|  8:39a|              1|\n",
      "|  7:32a|              1|\n",
      "|  6:56a|              1|\n",
      "|  5:04a|              1|\n",
      "|  6:14a|              1|\n",
      "|  5:13a|              1|\n",
      "|  8:04a|              1|\n",
      "|  6:05a|              1|\n",
      "|  5:27a|              1|\n",
      "|  6:24a|              1|\n",
      "|  7:58a|              1|\n",
      "|  5:47a|              1|\n",
      "|  6:38a|              2|\n",
      "|  9:07a|              1|\n",
      "|  6:21a|              1|\n",
      "+-------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Executa a query\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a query\n",
    "# Horário que teve mais de uma entrega\n",
    "query = \"\"\"\n",
    "SELECT horario, COUNT(*) AS hora_ultima_entrega\n",
    "FROM tb_logistica\n",
    "GROUP BY horario\n",
    "HAVING COUNT(*) > 1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+\n",
      "|horario|hora_ultima_entrega|\n",
      "+-------+-------------------+\n",
      "|  6:38a|                  2|\n",
      "+-------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Executa a query\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Podemos ainda fazer Pivot de um dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de horários de entregas\n",
    "lista_horarios = ['5:13a', '6:38a', '7:32a', '8:04a', '9:07a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+\n",
      "|id_veiculo|  entrega|horario|\n",
      "+----------+---------+-------+\n",
      "|       298|Entrega 2|  8:04a|\n",
      "|       298|Entrega 7|  9:07a|\n",
      "|       315|Entrega 4|  6:38a|\n",
      "|       315|Entrega 7|  7:32a|\n",
      "|       457|Entrega 2|  5:13a|\n",
      "|       457|Entrega 7|  6:38a|\n",
      "+----------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testamos o filtro\n",
    "df.filter(df.horario.isin(lista_horarios)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot é uma função de agregação no Spark\n",
    "df_pivot = df.filter(df.horario.isin(lista_horarios)).groupBy(\"id_veiculo\").pivot(\"horario\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-----+-----+-----+-----+\n",
      "|id_veiculo|5:13a|6:38a|7:32a|8:04a|9:07a|\n",
      "+----------+-----+-----+-----+-----+-----+\n",
      "|       298| null| null| null|    1|    1|\n",
      "|       457|    1|    1| null| null| null|\n",
      "|       315| null|    1|    1| null| null|\n",
      "+----------+-----+-----+-----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pivot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos converter o Spark Dataframe para Pandas Dataframe a fim de facilitar a visualização\n",
    "pandasDF = df_pivot.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_veiculo</th>\n",
       "      <th>5:13a</th>\n",
       "      <th>6:38a</th>\n",
       "      <th>7:32a</th>\n",
       "      <th>8:04a</th>\n",
       "      <th>9:07a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>298</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>457</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>315</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id_veiculo  5:13a  6:38a  7:32a  8:04a  9:07a\n",
       "0        298    NaN    NaN    NaN    1.0    1.0\n",
       "1        457    1.0    1.0    NaN    NaN    NaN\n",
       "2        315    NaN    1.0    1.0    NaN    NaN"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandasDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a query\n",
    "# Número de entregas por id_veiculo\n",
    "query = \"\"\"\n",
    "SELECT * FROM (\n",
    "  SELECT id_veiculo, horario\n",
    "  FROM tb_logistica\n",
    ")\n",
    "PIVOT (\n",
    "  COUNT(*)\n",
    "  FOR horario in (\n",
    "    '5:13a', '6:38a', '7:32a', '8:04a', '9:07a'\n",
    "  )\n",
    ")\n",
    "ORDER BY id_veiculo\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-----+-----+-----+-----+\n",
      "|id_veiculo|5:13a|6:38a|7:32a|8:04a|9:07a|\n",
      "+----------+-----+-----+-----+-----+-----+\n",
      "|       298| null| null| null|    1|    1|\n",
      "|       315| null|    1|    1| null| null|\n",
      "|       457|    1|    1| null| null| null|\n",
      "+----------+-----+-----+-----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Executa a query\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mjRN4rGu5bbe"
   },
   "source": [
    "## SQL Window Function Para Agregação ao Longo do Tempo\n",
    "\n",
    "Leia o manual em pdf no Capítulo 13 com a definição de Função Window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isso aqui é agregação por coluna (e por isso usamos o group by)\n",
    "query = \"\"\"\n",
    "SELECT id_veiculo, COUNT(horario) AS numero_entregas\n",
    "FROM tb_logistica\n",
    "GROUP BY id_veiculo\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+\n",
      "|id_veiculo|numero_entregas|\n",
      "+----------+---------------+\n",
      "|       298|              7|\n",
      "|       457|              7|\n",
      "|       315|              7|\n",
      "+----------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isso aqui é agregação por linha (e por isso usamos função window)\n",
    "# Isso é útil quando os dados estão embaralhados e queremos organizar com base em um critério\n",
    "# Por exemplo: \n",
    "# Para cada entrega (entrega 1, entrega 2, etc..), quais veículos fizeram a entrega primeiro em cada hora?\n",
    "query = \"\"\"\n",
    "SELECT id_veiculo, entrega, horario,\n",
    "ROW_NUMBER() OVER (PARTITION BY entrega ORDER BY horario) AS ranking\n",
    "FROM tb_logistica\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+-------+\n",
      "|id_veiculo|  entrega|horario|ranking|\n",
      "+----------+---------+-------+-------+\n",
      "|       457|Entrega 1|  5:04a|      1|\n",
      "|       315|Entrega 1|  6:05a|      2|\n",
      "|       298|Entrega 1|  7:58a|      3|\n",
      "|       457|Entrega 2|  5:13a|      1|\n",
      "|       315|Entrega 2|  6:14a|      2|\n",
      "|       298|Entrega 2|  8:04a|      3|\n",
      "|       457|Entrega 3|  5:27a|      1|\n",
      "|       315|Entrega 3|  6:24a|      2|\n",
      "|       298|Entrega 3|  8:17a|      3|\n",
      "|       457|Entrega 4|  5:39a|      1|\n",
      "|       315|Entrega 4|  6:38a|      2|\n",
      "|       298|Entrega 4|  8:28a|      3|\n",
      "|       457|Entrega 5|  5:47a|      1|\n",
      "|       315|Entrega 5|  6:45a|      2|\n",
      "|       298|Entrega 5|  8:33a|      3|\n",
      "|       457|Entrega 6|  6:21a|      1|\n",
      "|       315|Entrega 6|  6:56a|      2|\n",
      "|       298|Entrega 6|  8:39a|      3|\n",
      "|       457|Entrega 7|  6:38a|      1|\n",
      "|       315|Entrega 7|  7:32a|      2|\n",
      "|       298|Entrega 7|  9:07a|      3|\n",
      "+----------+---------+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(query).show(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+---+\n",
      "|id_veiculo|  entrega|horario| id|\n",
      "+----------+---------+-------+---+\n",
      "|       457|Entrega 1|  5:04a|  1|\n",
      "|       315|Entrega 1|  6:05a|  2|\n",
      "|       298|Entrega 1|  7:58a|  3|\n",
      "|       457|Entrega 2|  5:13a|  1|\n",
      "|       315|Entrega 2|  6:14a|  2|\n",
      "|       298|Entrega 2|  8:04a|  3|\n",
      "|       457|Entrega 3|  5:27a|  1|\n",
      "|       315|Entrega 3|  6:24a|  2|\n",
      "|       298|Entrega 3|  8:17a|  3|\n",
      "|       457|Entrega 4|  5:39a|  1|\n",
      "|       315|Entrega 4|  6:38a|  2|\n",
      "|       298|Entrega 4|  8:28a|  3|\n",
      "|       457|Entrega 5|  5:47a|  1|\n",
      "|       315|Entrega 5|  6:45a|  2|\n",
      "|       298|Entrega 5|  8:33a|  3|\n",
      "|       457|Entrega 6|  6:21a|  1|\n",
      "|       315|Entrega 6|  6:56a|  2|\n",
      "|       298|Entrega 6|  8:39a|  3|\n",
      "|       457|Entrega 7|  6:38a|  1|\n",
      "|       315|Entrega 7|  7:32a|  2|\n",
      "|       298|Entrega 7|  9:07a|  3|\n",
      "+----------+---------+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mesmo resultado anterior mas usando Função SparkSQL\n",
    "df.withColumn(\"id\", row_number().over(Window.partitionBy('entrega').orderBy('horario'))).show(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a query\n",
    "# Para cada entrega mostra o horário da entrega anterior por id_veiculo\n",
    "query = \"\"\"\n",
    "SELECT id_veiculo, entrega, horario, \n",
    "LAG(horario, 1) OVER (PARTITION BY id_veiculo ORDER BY horario) AS entrega_anterior \n",
    "FROM tb_logistica\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+----------------+\n",
      "|id_veiculo|  entrega|horario|entrega_anterior|\n",
      "+----------+---------+-------+----------------+\n",
      "|       298|Entrega 1|  7:58a|            null|\n",
      "|       298|Entrega 2|  8:04a|           7:58a|\n",
      "|       298|Entrega 3|  8:17a|           8:04a|\n",
      "|       298|Entrega 4|  8:28a|           8:17a|\n",
      "|       298|Entrega 5|  8:33a|           8:28a|\n",
      "|       298|Entrega 6|  8:39a|           8:33a|\n",
      "|       298|Entrega 7|  9:07a|           8:39a|\n",
      "|       315|Entrega 1|  6:05a|            null|\n",
      "|       315|Entrega 2|  6:14a|           6:05a|\n",
      "|       315|Entrega 3|  6:24a|           6:14a|\n",
      "|       315|Entrega 4|  6:38a|           6:24a|\n",
      "|       315|Entrega 5|  6:45a|           6:38a|\n",
      "|       315|Entrega 6|  6:56a|           6:45a|\n",
      "|       315|Entrega 7|  7:32a|           6:56a|\n",
      "|       457|Entrega 1|  5:04a|            null|\n",
      "|       457|Entrega 2|  5:13a|           5:04a|\n",
      "|       457|Entrega 3|  5:27a|           5:13a|\n",
      "|       457|Entrega 4|  5:39a|           5:27a|\n",
      "|       457|Entrega 5|  5:47a|           5:39a|\n",
      "|       457|Entrega 6|  6:21a|           5:47a|\n",
      "|       457|Entrega 7|  6:38a|           6:21a|\n",
      "+----------+---------+-------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(query).show(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "-nH-0ZBb5Uwz"
   },
   "outputs": [],
   "source": [
    "# Define a query\n",
    "# Para cada entrega mostra o horário da próxima entrega por id_veiculo\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "id_veiculo, entrega, horario, \n",
    "LEAD(horario, 1) OVER (PARTITION BY id_veiculo ORDER BY horario) AS proxima_entrega \n",
    "FROM tb_logistica\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nC8yheR855CD",
    "outputId": "0203f3c1-df75-4242-c3aa-6a18b249cdc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+---------------+\n",
      "|id_veiculo|  entrega|horario|proxima_entrega|\n",
      "+----------+---------+-------+---------------+\n",
      "|       298|Entrega 1|  7:58a|          8:04a|\n",
      "|       298|Entrega 2|  8:04a|          8:17a|\n",
      "|       298|Entrega 3|  8:17a|          8:28a|\n",
      "|       298|Entrega 4|  8:28a|          8:33a|\n",
      "|       298|Entrega 5|  8:33a|          8:39a|\n",
      "|       298|Entrega 6|  8:39a|          9:07a|\n",
      "|       298|Entrega 7|  9:07a|           null|\n",
      "|       315|Entrega 1|  6:05a|          6:14a|\n",
      "|       315|Entrega 2|  6:14a|          6:24a|\n",
      "|       315|Entrega 3|  6:24a|          6:38a|\n",
      "|       315|Entrega 4|  6:38a|          6:45a|\n",
      "|       315|Entrega 5|  6:45a|          6:56a|\n",
      "|       315|Entrega 6|  6:56a|          7:32a|\n",
      "|       315|Entrega 7|  7:32a|           null|\n",
      "|       457|Entrega 1|  5:04a|          5:13a|\n",
      "|       457|Entrega 2|  5:13a|          5:27a|\n",
      "|       457|Entrega 3|  5:27a|          5:39a|\n",
      "|       457|Entrega 4|  5:39a|          5:47a|\n",
      "|       457|Entrega 5|  5:47a|          6:21a|\n",
      "|       457|Entrega 6|  6:21a|          6:38a|\n",
      "|       457|Entrega 7|  6:38a|           null|\n",
      "+----------+---------+-------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Executa a query e mostra o resultado\n",
    "spark.sql(query).show(21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bh-BXgGhSdMy"
   },
   "source": [
    "## Usando Partições com Spark SQL\n",
    "* A função **over()** no Spark SQL corresponde a cláusula **OVER** em SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bEHz-VD8TIfW",
    "outputId": "30f1d75b-be2b-4fbc-f1a0-37e17652d058"
   },
   "outputs": [],
   "source": [
    "# Abre a janela nos dados\n",
    "janela = Window.partitionBy('id_veiculo').orderBy('horario')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.window.WindowSpec"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(janela)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplica o Lead (desloca os dados no tempo) sobre (over) a janela (window)\n",
    "dfx = df.withColumn('proxima_entrega', lead('horario', 1).over(janela))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+---------------+\n",
      "|id_veiculo|  entrega|horario|proxima_entrega|\n",
      "+----------+---------+-------+---------------+\n",
      "|       298|Entrega 1|  7:58a|          8:04a|\n",
      "|       298|Entrega 2|  8:04a|          8:17a|\n",
      "|       298|Entrega 3|  8:17a|          8:28a|\n",
      "|       298|Entrega 4|  8:28a|          8:33a|\n",
      "|       298|Entrega 5|  8:33a|          8:39a|\n",
      "|       298|Entrega 6|  8:39a|          9:07a|\n",
      "|       298|Entrega 7|  9:07a|           null|\n",
      "|       315|Entrega 1|  6:05a|          6:14a|\n",
      "|       315|Entrega 2|  6:14a|          6:24a|\n",
      "|       315|Entrega 3|  6:24a|          6:38a|\n",
      "|       315|Entrega 4|  6:38a|          6:45a|\n",
      "|       315|Entrega 5|  6:45a|          6:56a|\n",
      "|       315|Entrega 6|  6:56a|          7:32a|\n",
      "|       315|Entrega 7|  7:32a|           null|\n",
      "|       457|Entrega 1|  5:04a|          5:13a|\n",
      "|       457|Entrega 2|  5:13a|          5:27a|\n",
      "|       457|Entrega 3|  5:27a|          5:39a|\n",
      "|       457|Entrega 4|  5:39a|          5:47a|\n",
      "|       457|Entrega 5|  5:47a|          6:21a|\n",
      "|       457|Entrega 6|  6:21a|          6:38a|\n",
      "|       457|Entrega 7|  6:38a|           null|\n",
      "+----------+---------+-------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfx.show(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M4lokvB9V3Ss",
    "outputId": "0817c7dd-b755-4f99-80cb-25f874ce0669"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+---------------+\n",
      "|id_veiculo|  entrega|horario|proxima_entrega|\n",
      "+----------+---------+-------+---------------+\n",
      "|       298|Entrega 1|  7:58a|          8:04a|\n",
      "|       298|Entrega 2|  8:04a|          8:17a|\n",
      "|       298|Entrega 3|  8:17a|          8:28a|\n",
      "|       298|Entrega 4|  8:28a|          8:33a|\n",
      "|       298|Entrega 5|  8:33a|          8:39a|\n",
      "|       298|Entrega 6|  8:39a|          9:07a|\n",
      "|       298|Entrega 7|  9:07a|           null|\n",
      "|       315|Entrega 1|  6:05a|          6:14a|\n",
      "|       315|Entrega 2|  6:14a|          6:24a|\n",
      "|       315|Entrega 3|  6:24a|          6:38a|\n",
      "|       315|Entrega 4|  6:38a|          6:45a|\n",
      "|       315|Entrega 5|  6:45a|          6:56a|\n",
      "|       315|Entrega 6|  6:56a|          7:32a|\n",
      "|       315|Entrega 7|  7:32a|           null|\n",
      "|       457|Entrega 1|  5:04a|          5:13a|\n",
      "|       457|Entrega 2|  5:13a|          5:27a|\n",
      "|       457|Entrega 3|  5:27a|          5:39a|\n",
      "|       457|Entrega 4|  5:39a|          5:47a|\n",
      "|       457|Entrega 5|  5:47a|          6:21a|\n",
      "|       457|Entrega 6|  6:21a|          6:38a|\n",
      "|       457|Entrega 7|  6:38a|           null|\n",
      "+----------+---------+-------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mesmo exemplo anterior mas em uma linha de código\n",
    "df_dot = df.withColumn('proxima_entrega', lead('horario', 1)\n",
    ".over(Window.partitionBy('id_veiculo')\n",
    ".orderBy('horario'))).show(21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse de Data Para Agregação ao Longo do Tempo\n",
    "\n",
    "Calcule o tempo (em minutos) para a próxima entrega de cada veículo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[key: string, value: string]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define o time parser policy\n",
    "spark.sql(\"set spark.sql.legacy.timeParserPolicy=LEGACY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hHLu3CrNWpj2",
    "outputId": "c544b7a5-7ae9-4b1d-e35b-f02981fa7f08"
   },
   "outputs": [],
   "source": [
    "# Cria a janela\n",
    "window = Window.partitionBy('id_veiculo').orderBy('horario')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+---------------------+\n",
      "|id_veiculo|  entrega|horario|tempo_proxima_entrega|\n",
      "+----------+---------+-------+---------------------+\n",
      "|       298|Entrega 1|  7:58a|                  6.0|\n",
      "|       298|Entrega 2|  8:04a|                 13.0|\n",
      "|       298|Entrega 3|  8:17a|                 11.0|\n",
      "|       298|Entrega 4|  8:28a|                  5.0|\n",
      "|       298|Entrega 5|  8:33a|                  6.0|\n",
      "|       298|Entrega 6|  8:39a|                 28.0|\n",
      "|       298|Entrega 7|  9:07a|                 null|\n",
      "|       315|Entrega 1|  6:05a|                  9.0|\n",
      "|       315|Entrega 2|  6:14a|                 10.0|\n",
      "|       315|Entrega 3|  6:24a|                 14.0|\n",
      "|       315|Entrega 4|  6:38a|                  7.0|\n",
      "|       315|Entrega 5|  6:45a|                 11.0|\n",
      "|       315|Entrega 6|  6:56a|                 36.0|\n",
      "|       315|Entrega 7|  7:32a|                 null|\n",
      "|       457|Entrega 1|  5:04a|                  9.0|\n",
      "|       457|Entrega 2|  5:13a|                 14.0|\n",
      "|       457|Entrega 3|  5:27a|                 12.0|\n",
      "|       457|Entrega 4|  5:39a|                  8.0|\n",
      "|       457|Entrega 5|  5:47a|                 34.0|\n",
      "|       457|Entrega 6|  6:21a|                 17.0|\n",
      "|       457|Entrega 7|  6:38a|                 null|\n",
      "+----------+---------+-------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Agregação por linha para calcular a diferença entre os horários\n",
    "dot_df = df.withColumn('tempo_proxima_entrega', \n",
    "                       (unix_timestamp(lead('horario', 1).over(window),'H:m') \n",
    "                        - unix_timestamp('horario', 'H:m'))/60).show(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "noXmj-6VXk4t",
    "outputId": "8b4b4e81-abad-4884-b840-30016c57d7ad"
   },
   "outputs": [],
   "source": [
    "# Define a query\n",
    "# Calculamos aqui a diferença de tempo de uma entrega para outra por id_veiculo (partição)\n",
    "query = \"\"\"\n",
    "SELECT *, \n",
    "(UNIX_TIMESTAMP(LEAD(horario, 1) OVER (PARTITION BY id_veiculo ORDER BY horario),'H:m') \n",
    "- UNIX_TIMESTAMP(horario, 'H:m'))/60 AS tempo_proxima_entrega\n",
    "FROM tb_logistica \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_df = spark.sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+---------------------+\n",
      "|id_veiculo|  entrega|horario|tempo_proxima_entrega|\n",
      "+----------+---------+-------+---------------------+\n",
      "|       298|Entrega 1|  7:58a|                  6.0|\n",
      "|       298|Entrega 2|  8:04a|                 13.0|\n",
      "|       298|Entrega 3|  8:17a|                 11.0|\n",
      "|       298|Entrega 4|  8:28a|                  5.0|\n",
      "|       298|Entrega 5|  8:33a|                  6.0|\n",
      "|       298|Entrega 6|  8:39a|                 28.0|\n",
      "|       298|Entrega 7|  9:07a|                 null|\n",
      "|       315|Entrega 1|  6:05a|                  9.0|\n",
      "|       315|Entrega 2|  6:14a|                 10.0|\n",
      "|       315|Entrega 3|  6:24a|                 14.0|\n",
      "|       315|Entrega 4|  6:38a|                  7.0|\n",
      "|       315|Entrega 5|  6:45a|                 11.0|\n",
      "|       315|Entrega 6|  6:56a|                 36.0|\n",
      "|       315|Entrega 7|  7:32a|                 null|\n",
      "|       457|Entrega 1|  5:04a|                  9.0|\n",
      "|       457|Entrega 2|  5:13a|                 14.0|\n",
      "|       457|Entrega 3|  5:27a|                 12.0|\n",
      "|       457|Entrega 4|  5:39a|                  8.0|\n",
      "|       457|Entrega 5|  5:47a|                 34.0|\n",
      "|       457|Entrega 6|  6:21a|                 17.0|\n",
      "|       457|Entrega 7|  6:38a|                 null|\n",
      "+----------+---------+-------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql_df.show(21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "429SVArhYq6A"
   },
   "source": [
    "# Fim"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Pyspark SQL.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
