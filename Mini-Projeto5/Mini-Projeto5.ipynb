{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Data Science Academy</font>\n",
    "# <font color='blue'>Big Data Real-Time Analytics com Python e Spark</font>\n",
    "\n",
    "## <font color='blue'>Mini-Projeto 5</font>\n",
    "\n",
    "### <font color='blue'>Machine Learning na Engenharia Civil com Apache Spark</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leia os manuais em pdf no Capítulo 14 do curso com a definição do problema e a fonte de dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](imagens/MP5.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versão da Linguagem Python Usada Neste Jupyter Notebook: 3.9.7\n"
     ]
    }
   ],
   "source": [
    "# Versão da Linguagem Python\n",
    "from platform import python_version\n",
    "print('Versão da Linguagem Python Usada Neste Jupyter Notebook:', python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para atualizar um pacote, execute o comando abaixo no terminal ou prompt de comando:\n",
    "# pip install -U nome_pacote\n",
    "\n",
    "# Para instalar a versão exata de um pacote, execute o comando abaixo no terminal ou prompt de comando:\n",
    "#!pip install nome_pacote==versão_desejada\n",
    "\n",
    "# Depois de instalar ou atualizar o pacote, reinicie o jupyter notebook.\n",
    "\n",
    "# Instala o pacote watermark. \n",
    "# Esse pacote é usado para gravar as versões de outros pacotes usados neste jupyter notebook.\n",
    "#!pip install -q -U watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa o findspark e inicializa\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import * \n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import MinMaxScaler\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.ml.regression import *\n",
    "from pyspark.ml.evaluation import *\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Data Science Academy\n",
      "\n",
      "findspark: 2.0.1\n",
      "pyspark  : 3.3.0\n",
      "sys      : 3.9.7 (default, Sep 16 2021, 08:50:36) \n",
      "[Clang 10.0.0 ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Versões dos pacotes usados neste jupyter notebook\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Data Science Academy\" --iversions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o Ambiente Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/08/31 19:26:09 WARN Utils: Your hostname, falcon.local resolves to a loopback address: 127.0.0.1; using 10.0.0.87 instead (on interface en0)\n",
      "22/08/31 19:26:09 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/08/31 19:26:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Criando o Spark Context\n",
    "sc = SparkContext(appName = \"Mini-Projeto5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando a sessão\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.0.0.87:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Mini-Projeto5</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f9b17a26f10>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando o Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega os dados\n",
    "dados = spark.read.csv('dados/dataset.csv', inferSchema = True, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1030"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Número de registros\n",
    "dados.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+------+-----+----------------+---------------+-------------+---+-----+\n",
      "|cement| slag|flyash|water|superplasticizer|coarseaggregate|fineaggregate|age|csMPa|\n",
      "+------+-----+------+-----+----------------+---------------+-------------+---+-----+\n",
      "| 540.0|  0.0|   0.0|162.0|             2.5|         1040.0|        676.0| 28|79.99|\n",
      "| 540.0|  0.0|   0.0|162.0|             2.5|         1055.0|        676.0| 28|61.89|\n",
      "| 332.5|142.5|   0.0|228.0|             0.0|          932.0|        594.0|270|40.27|\n",
      "| 332.5|142.5|   0.0|228.0|             0.0|          932.0|        594.0|365|41.05|\n",
      "| 198.6|132.4|   0.0|192.0|             0.0|          978.4|        825.5|360| 44.3|\n",
      "| 266.0|114.0|   0.0|228.0|             0.0|          932.0|        670.0| 90|47.03|\n",
      "| 380.0| 95.0|   0.0|228.0|             0.0|          932.0|        594.0|365| 43.7|\n",
      "| 380.0| 95.0|   0.0|228.0|             0.0|          932.0|        594.0| 28|36.45|\n",
      "| 266.0|114.0|   0.0|228.0|             0.0|          932.0|        670.0| 28|45.85|\n",
      "| 475.0|  0.0|   0.0|228.0|             0.0|          932.0|        594.0| 28|39.29|\n",
      "+------+-----+------+-----+----------------+---------------+-------------+---+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Visualiza os dados no padrão do Spark DataFrame\n",
    "dados.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cement</th>\n",
       "      <th>slag</th>\n",
       "      <th>flyash</th>\n",
       "      <th>water</th>\n",
       "      <th>superplasticizer</th>\n",
       "      <th>coarseaggregate</th>\n",
       "      <th>fineaggregate</th>\n",
       "      <th>age</th>\n",
       "      <th>csMPa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>266.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>90</td>\n",
       "      <td>47.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>380.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>43.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>380.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>28</td>\n",
       "      <td>36.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>266.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>28</td>\n",
       "      <td>45.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>475.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>28</td>\n",
       "      <td>39.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cement   slag  flyash  water  superplasticizer  coarseaggregate  \\\n",
       "0   540.0    0.0     0.0  162.0               2.5           1040.0   \n",
       "1   540.0    0.0     0.0  162.0               2.5           1055.0   \n",
       "2   332.5  142.5     0.0  228.0               0.0            932.0   \n",
       "3   332.5  142.5     0.0  228.0               0.0            932.0   \n",
       "4   198.6  132.4     0.0  192.0               0.0            978.4   \n",
       "5   266.0  114.0     0.0  228.0               0.0            932.0   \n",
       "6   380.0   95.0     0.0  228.0               0.0            932.0   \n",
       "7   380.0   95.0     0.0  228.0               0.0            932.0   \n",
       "8   266.0  114.0     0.0  228.0               0.0            932.0   \n",
       "9   475.0    0.0     0.0  228.0               0.0            932.0   \n",
       "\n",
       "   fineaggregate  age  csMPa  \n",
       "0          676.0   28  79.99  \n",
       "1          676.0   28  61.89  \n",
       "2          594.0  270  40.27  \n",
       "3          594.0  365  41.05  \n",
       "4          825.5  360  44.30  \n",
       "5          670.0   90  47.03  \n",
       "6          594.0  365  43.70  \n",
       "7          594.0   28  36.45  \n",
       "8          670.0   28  45.85  \n",
       "9          594.0   28  39.29  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualiza os dados no formato do Pandas\n",
    "dados.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cement: double (nullable = true)\n",
      " |-- slag: double (nullable = true)\n",
      " |-- flyash: double (nullable = true)\n",
      " |-- water: double (nullable = true)\n",
      " |-- superplasticizer: double (nullable = true)\n",
      " |-- coarseaggregate: double (nullable = true)\n",
      " |-- fineaggregate: double (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- csMPa: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Schema\n",
    "dados.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Módulo de Automação da Preparação de Dados\n",
    "\n",
    "O MLlib requer que todas as colunas de entrada do dataframe sejam vetorizadas. Vamos criar uma função Python que irá automatizar nosso trabalho de preparação dos dados, incluindo a vetorização e todas as tarefas necessárias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro, vamos listar e remover valores ausentes (se existirem). Vamos focar neste projeto em Machine Learning, mas lembre-se sempre de checar valores ausentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de linhas antes de remover valores ausentes: 1030\n",
      "Número de linhas após remover valores ausentes: 1030\n"
     ]
    }
   ],
   "source": [
    "# Separamos os dados ausentes (se existirem) e removemos (se existirem)\n",
    "dados_com_linhas_removidas = dados.na.drop()\n",
    "print('Número de linhas antes de remover valores ausentes:', dados.count())\n",
    "print('Número de linhas após remover valores ausentes:', dados_com_linhas_removidas.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de preparação dos dados\n",
    "def func_modulo_prep_dados(df,\n",
    "                           variaveis_entrada,\n",
    "                           variavel_saida,\n",
    "                           tratar_outliers = True,\n",
    "                           padronizar_dados = True):\n",
    "\n",
    "    # Vamos gerar um novo dataframe, renomeando o argumento que representa a variável de saída.\n",
    "    novo_df = df.withColumnRenamed(variavel_saida, 'label')\n",
    "    \n",
    "    # Convertemos a variável alvo para o tipo numérico como float (encoding)\n",
    "    if str(novo_df.schema['label'].dataType) != 'IntegerType':\n",
    "        novo_df = novo_df.withColumn(\"label\", novo_df[\"label\"].cast(FloatType()))\n",
    "    \n",
    "    # Listas de controle para as variáveis\n",
    "    variaveis_numericas = []\n",
    "    variaveis_categoricas = []\n",
    "    \n",
    "    # Se tiver variáveis de entrada do tipo string, convertemos para o tipo numérico\n",
    "    for coluna in variaveis_entrada:\n",
    "        \n",
    "        # Verifica se a variável é do tipo string\n",
    "        if str(novo_df.schema[coluna].dataType) == 'StringType':\n",
    "            \n",
    "            # Definimos a variável com um sufixo\n",
    "            novo_nome_coluna = coluna + \"_num\"\n",
    "            \n",
    "            # Adicionamos à lista de variáveis categóricas\n",
    "            variaveis_categoricas.append(novo_nome_coluna)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            # Se não for variável do tipo string, então é numérica e adicionamos na lista correspondente\n",
    "            variaveis_numericas.append(coluna)\n",
    "            \n",
    "            # Colocamos os dados no dataframe de variáveis indexadas\n",
    "            df_indexed = novo_df\n",
    "            \n",
    "    # Se o dataframe tiver dados do tipo string, aplicamos a indexação\n",
    "    # Verificamos se a lista de variáveis categóricas não está vazia\n",
    "    if len(variaveis_categoricas) != 0: \n",
    "        \n",
    "        # Loop pelas colunas\n",
    "        for coluna in novo_df:\n",
    "            \n",
    "            # Se a variável é do tipo string, criamos, treinamos e aplicamos o indexador\n",
    "            if str(novo_df.schema[coluna].dataType) == 'StringType':\n",
    "                \n",
    "                # Cria o indexador\n",
    "                indexer = StringIndexer(inputCol = coluna, outputCol = coluna + \"_num\") \n",
    "                \n",
    "                # Treina e aplica o indexador\n",
    "                df_indexed = indexer.fit(novo_df).transform(novo_df)\n",
    "    else:\n",
    "        \n",
    "        # Se não temos mais variáveis categóricas, então colocamos os dados no dataframe de variáveis indexadas\n",
    "        df_indexed = novo_df\n",
    "        \n",
    "    # Se for necessário tratar outliers, faremos isso agora\n",
    "    if tratar_outliers == True:\n",
    "        print(\"\\nAplicando o tratamento de outliers...\")\n",
    "        \n",
    "        # Dicionário\n",
    "        d = {}\n",
    "        \n",
    "        # Dicionário de quartis das variáveis do dataframe indexado (somente variáveis numéricas)\n",
    "        for col in variaveis_numericas: \n",
    "            d[col] = df_indexed.approxQuantile(col,[0.01, 0.99], 0.25) \n",
    "        \n",
    "        # Agora aplicamos transformação dependendo da distribuição de cada variável\n",
    "        for col in variaveis_numericas:\n",
    "            \n",
    "            # Extraímos a assimetria dos dados e usamos isso para tratar os outliers\n",
    "            skew = df_indexed.agg(skewness(df_indexed[col])).collect() \n",
    "            skew = skew[0][0]\n",
    "            \n",
    "            # Verificamos a assimetria e então aplicamos:\n",
    "            \n",
    "            # Transformação de log + 1 se a assimetria for positiva\n",
    "            if skew > 1:\n",
    "                indexed = df_indexed.withColumn(col, log(when(df[col] < d[col][0], d[col][0])\\\n",
    "                .when(df_indexed[col] > d[col][1], d[col][1])\\\n",
    "                .otherwise(df_indexed[col] ) + 1).alias(col))\n",
    "                print(\"\\nA variável \" + col + \" foi tratada para assimetria positiva (direita) com skew =\", skew)\n",
    "            \n",
    "            # Transformação exponencial se a assimetria for negativa\n",
    "            elif skew < -1:\n",
    "                indexed = df_indexed.withColumn(col, \\\n",
    "                exp(when(df[col] < d[col][0], d[col][0])\\\n",
    "                .when(df_indexed[col] > d[col][1], d[col][1])\\\n",
    "                .otherwise(df_indexed[col] )).alias(col))\n",
    "                print(\"\\nA variável \" + col + \" foi tratada para assimetria negativa (esquerda) com skew =\", skew)\n",
    "                \n",
    "            # Assimetria entre -1 e 1 não precisamos aplicar transformação aos dados\n",
    "\n",
    "    # Vetorização\n",
    "    \n",
    "    # Lista final de atributos\n",
    "    lista_atributos = variaveis_numericas + variaveis_categoricas\n",
    "    \n",
    "    # Cria o vetorizador para os atributos\n",
    "    vetorizador = VectorAssembler(inputCols = lista_atributos, outputCol = 'features')\n",
    "    \n",
    "    # Aplica o vetorizador ao conjunto de dados\n",
    "    dados_vetorizados = vetorizador.transform(df_indexed).select('features', 'label')\n",
    "    \n",
    "    # Se a flag padronizar_dados está como True, então padronizamos os dados colocando-os na mesma escala\n",
    "    if padronizar_dados == True:\n",
    "        print(\"\\nPadronizando o conjunto de dados para o intervalo de 0 a 1...\")\n",
    "        \n",
    "        # Cria o scaler\n",
    "        scaler = MinMaxScaler(inputCol = \"features\", outputCol = \"scaledFeatures\")\n",
    "\n",
    "        # Calcula o sumário de estatísticas e gera o padronizador\n",
    "        global scalerModel\n",
    "        scalerModel = scaler.fit(dados_vetorizados)\n",
    "\n",
    "        # Padroniza as variáveis para o intervalo [min, max]\n",
    "        dados_padronizados = scalerModel.transform(dados_vetorizados)\n",
    "        \n",
    "        # Gera os dados finais\n",
    "        dados_finais = dados_padronizados.select('label', 'scaledFeatures')\n",
    "        \n",
    "        # Renomeia as colunas (requerido pelo Spark)\n",
    "        dados_finais = dados_finais.withColumnRenamed('scaledFeatures', 'features')\n",
    "        \n",
    "        print(\"\\nProcesso Concluído!\")\n",
    "\n",
    "    # Se a flag está como False, então não padronizamos os dados\n",
    "    else:\n",
    "        print(\"\\nOs dados não serão padronizados pois a flag padronizar_dados está com o valor False.\")\n",
    "        dados_finais = dados_vetorizados\n",
    "    \n",
    "    return dados_finais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Agora aplicamos o módulo de preparação dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de variáveis de entrada (todas menos a última)\n",
    "variaveis_entrada = dados.columns[:-1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variável alvo\n",
    "variavel_saida = dados.columns[-1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Aplicando o tratamento de outliers...\n",
      "\n",
      "A variável age foi tratada para assimetria positiva (direita) com skew = 3.2644145354168086\n",
      "\n",
      "Padronizando o conjunto de dados para o intervalo de 0 a 1...\n",
      "\n",
      "Processo Concluído!\n"
     ]
    }
   ],
   "source": [
    "# Aplica a função\n",
    "dados_finais = func_modulo_prep_dados(dados, variaveis_entrada, variavel_saida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------------------------------------------------------------------------------------------------------------------+\n",
      "|label|features                                                                                                                      |\n",
      "+-----+------------------------------------------------------------------------------------------------------------------------------+\n",
      "|79.99|[1.0,0.0,0.0,0.3210862619808307,0.07763975155279502,0.6947674418604651,0.20572002007024587,0.07417582417582418]               |\n",
      "|61.89|[1.0,0.0,0.0,0.3210862619808307,0.07763975155279502,0.7383720930232558,0.20572002007024587,0.07417582417582418]               |\n",
      "|40.27|[0.526255707762557,0.3964941569282137,0.0,0.8482428115015974,0.0,0.3808139534883721,0.0,0.739010989010989]                    |\n",
      "|41.05|[0.526255707762557,0.3964941569282137,0.0,0.8482428115015974,0.0,0.3808139534883721,0.0,1.0]                                  |\n",
      "|44.3 |[0.22054794520547943,0.3683917640511965,0.0,0.560702875399361,0.0,0.5156976744186046,0.58078273958856,0.9862637362637363]     |\n",
      "|47.03|[0.3744292237442922,0.31719532554257096,0.0,0.8482428115015974,0.0,0.3808139534883721,0.19066733567486202,0.24450549450549453]|\n",
      "|43.7 |[0.634703196347032,0.2643294379521425,0.0,0.8482428115015974,0.0,0.3808139534883721,0.0,1.0]                                  |\n",
      "|36.45|[0.634703196347032,0.2643294379521425,0.0,0.8482428115015974,0.0,0.3808139534883721,0.0,0.07417582417582418]                  |\n",
      "|45.85|[0.3744292237442922,0.31719532554257096,0.0,0.8482428115015974,0.0,0.3808139534883721,0.19066733567486202,0.07417582417582418]|\n",
      "|39.29|(8,[0,3,5,7],[0.8515981735159817,0.8482428115015974,0.3808139534883721,0.07417582417582418])                                  |\n",
      "+-----+------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Visualiza\n",
    "dados_finais.show(10, truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificando a Correlação\n",
    "\n",
    "Vamos nos certificar de que não temos multicolinearidade antes de prosseguirmos. Lembre-se das seguintes diretrizes para o Coeficiente de Correlação de Pearson:\n",
    "\n",
    "- .00-.19 (correlação muito fraca)\n",
    "- .20-.39 (correlação fraca)\n",
    "- .40-.59 (correlação moderada)\n",
    "- .60-.79 (correlação forte)\n",
    "- .80-1.0 (correlação muito forte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrai a correlação\n",
    "coeficientes_corr = Correlation.corr(dados_finais, 'features', 'pearson').collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converte o resultado em array\n",
    "array_corr = coeficientes_corr.toArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.27521591, -0.39746734, -0.08158675,  0.09238617,\n",
       "        -0.10934899, -0.22271785,  0.08194602],\n",
       "       [-0.27521591,  1.        , -0.3235799 ,  0.10725203,  0.04327042,\n",
       "        -0.28399861, -0.28160267, -0.04424602],\n",
       "       [-0.39746734, -0.3235799 ,  1.        , -0.25698402,  0.37750315,\n",
       "        -0.00996083,  0.07910849, -0.15437052],\n",
       "       [-0.08158675,  0.10725203, -0.25698402,  1.        , -0.65753291,\n",
       "        -0.1822936 , -0.45066117,  0.27761822],\n",
       "       [ 0.09238617,  0.04327042,  0.37750315, -0.65753291,  1.        ,\n",
       "        -0.26599915,  0.22269123, -0.19270003],\n",
       "       [-0.10934899, -0.28399861, -0.00996083, -0.1822936 , -0.26599915,\n",
       "         1.        , -0.17848096, -0.00301588],\n",
       "       [-0.22271785, -0.28160267,  0.07910849, -0.45066117,  0.22269123,\n",
       "        -0.17848096,  1.        , -0.1560947 ],\n",
       "       [ 0.08194602, -0.04424602, -0.15437052,  0.27761822, -0.19270003,\n",
       "        -0.00301588, -0.1560947 ,  1.        ]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08194602387182176\n",
      "-0.044246019304454175\n",
      "-0.15437051606792915\n",
      "0.27761822152100296\n",
      "-0.19270002804347258\n",
      "-0.0030158803467436645\n",
      "-0.15609470264758615\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Lista a correlação entre os atributos e a variável alvo\n",
    "for item in array_corr:\n",
    "    print(item[7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divisão em Dados de Treino e Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisão com proporção 70/30\n",
    "dados_treino, dados_teste = dados_finais.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Módulo de AutoML (Automated Machine Learning)\n",
    "\n",
    "https://spark.apache.org/docs/latest/ml-classification-regression.html#regression\n",
    "\n",
    "Vamos criar uma função para automatizar o uso de diversos algoritmos. Nossa função irá criar, treinar e avaliar cada um deles com diferentes combinações de hiperparâmetros. E então escolheremos o modelo de melhor performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Módulo de Machine Learning\n",
    "def func_modulo_ml(algoritmo_regressao):\n",
    "\n",
    "    # Função para obter o tipo do algoritmo de regressão e criar a instância do objeto\n",
    "    # Usaremos isso para automatizar nosso processo\n",
    "    def func_tipo_algo(algo_regressao):\n",
    "        algoritmo = algo_regressao\n",
    "        tipo_algo = type(algoritmo).__name__\n",
    "        return tipo_algo\n",
    "    \n",
    "    # Aplica a função anterior\n",
    "    tipo_algo = func_tipo_algo(algoritmo_regressao)\n",
    "\n",
    "    # Se o algoritmo for Regressão Linear, entramos neste bloco if\n",
    "    if tipo_algo == \"LinearRegression\":\n",
    "        \n",
    "        # Treinamos a primeira versão do modelo sem validação cruzada\n",
    "        modelo = regressor.fit(dados_treino)\n",
    "        \n",
    "        # Métricas do modelo\n",
    "        print('\\033[1m' + \"Modelo de Regressão Linear Sem Validação Cruzada:\" + '\\033[0m')\n",
    "        print(\"\")\n",
    "        \n",
    "        # Avalia o modelo com dados de teste\n",
    "        resultado_teste = modelo.evaluate(dados_teste)\n",
    "\n",
    "        # Imprime as métricas de erro do modelo com dados de teste\n",
    "        print(\"RMSE em Teste: {}\".format(resultado_teste.rootMeanSquaredError))\n",
    "        print(\"Coeficiente R2 em Teste: {}\".format(resultado_teste.r2))\n",
    "        print(\"\")\n",
    "        \n",
    "        # Agora vamos criar a segunda versão do modelo com mesmo algoritmo, mas usando validação cruzada\n",
    "        \n",
    "        # Prepara o grid de hiperparâmetros\n",
    "        paramGrid = (ParamGridBuilder().addGrid(regressor.regParam, [0.1, 0.01]).build())\n",
    "        \n",
    "        # Cria os avaliadores\n",
    "        eval_rmse = RegressionEvaluator(metricName = \"rmse\")\n",
    "        eval_r2 = RegressionEvaluator(metricName = \"r2\")\n",
    "        \n",
    "        # Cria o Cross Validator\n",
    "        crossval = CrossValidator(estimator = regressor,\n",
    "                                  estimatorParamMaps = paramGrid,\n",
    "                                  evaluator = eval_rmse,\n",
    "                                  numFolds = 3) \n",
    "        \n",
    "        print('\\033[1m' + \"Modelo de Regressão Linear Com Validação Cruzada:\" + '\\033[0m')\n",
    "        print(\"\")\n",
    "        \n",
    "        # Treina o modelo com validação cruzada\n",
    "        modelo = crossval.fit(dados_treino)\n",
    "        \n",
    "        # Salva o melhor modelo da versão 2\n",
    "        global LR_BestModel \n",
    "        LR_BestModel = modelo.bestModel\n",
    "                \n",
    "        # Previsões com dados de teste\n",
    "        previsoes = LR_BestModel.transform(dados_teste)\n",
    "        \n",
    "        # Avaliação do melhor modelo\n",
    "        resultado_teste_rmse = eval_rmse.evaluate(previsoes)\n",
    "        print('RMSE em Teste:', resultado_teste_rmse)\n",
    "        \n",
    "        resultado_teste_r2 = eval_r2.evaluate(previsoes)\n",
    "        print('Coeficiente R2 em Teste:', resultado_teste_r2)\n",
    "        print(\"\")\n",
    "    \n",
    "        # Lista de colunas para colocar no dataframe de resumo\n",
    "        columns = ['Regressor', 'Resultado_RMSE', 'Resultado_R2']\n",
    "        \n",
    "        # Formata os resultados e cria o dataframe\n",
    "        \n",
    "        # Formata as métricas e nome do algoritmo\n",
    "        rmse_str = [str(resultado_teste_rmse)] \n",
    "        r2_str = [str(resultado_teste_r2)] \n",
    "        tipo_algo = [tipo_algo] \n",
    "        \n",
    "        # Cria o dataframne\n",
    "        df_resultado = spark.createDataFrame(zip(tipo_algo, rmse_str, r2_str), schema = columns)\n",
    "        \n",
    "        # Grava os resultados no dataframe\n",
    "        df_resultado = df_resultado.withColumn('Resultado_RMSE', df_resultado.Resultado_RMSE.substr(0, 5))\n",
    "        df_resultado = df_resultado.withColumn('Resultado_R2', df_resultado.Resultado_R2.substr(0, 5))\n",
    "        \n",
    "        return df_resultado\n",
    "\n",
    "    else:\n",
    "        \n",
    "        # Verificamos se o algoritmo é o Decision Tree e criamos o grid de hiperparâmetros\n",
    "        if tipo_algo in(\"DecisionTreeRegressor\"):\n",
    "            paramGrid = (ParamGridBuilder().addGrid(regressor.maxBins, [10, 20, 40]).build())\n",
    "\n",
    "        # Verificamos se o algoritmo é o Random Forest e criamos o grid de hiperparâmetros\n",
    "        if tipo_algo in(\"RandomForestRegressor\"):\n",
    "            paramGrid = (ParamGridBuilder().addGrid(regressor.numTrees, [5, 20]).build())\n",
    "\n",
    "        # Verificamos se o algoritmo é o GBT e criamos o grid de hiperparâmetros\n",
    "        if tipo_algo in(\"GBTRegressor\"):\n",
    "            paramGrid = (ParamGridBuilder() \\\n",
    "                         .addGrid(regressor.maxBins, [10, 20]) \\\n",
    "                         .addGrid(regressor.maxIter, [10, 15])\n",
    "                         .build())\n",
    "            \n",
    "        # Verificamos se o algoritmo é o Isotonic \n",
    "        if tipo_algo in(\"IsotonicRegression\"):\n",
    "            paramGrid = (ParamGridBuilder().addGrid(regressor.isotonic, [True, False]).build())\n",
    "\n",
    "        # Cria os avaliadores\n",
    "        eval_rmse = RegressionEvaluator(metricName = \"rmse\")\n",
    "        eval_r2 = RegressionEvaluator(metricName = \"r2\")\n",
    "        \n",
    "        # Prepara o Cross Validator\n",
    "        crossval = CrossValidator(estimator = regressor,\n",
    "                                  estimatorParamMaps = paramGrid,\n",
    "                                  evaluator = eval_rmse,\n",
    "                                  numFolds = 3) \n",
    "        \n",
    "        # Treina o modelo usando validação cruzada\n",
    "        modelo = crossval.fit(dados_treino)\n",
    "        \n",
    "        # Extrai o melhor modelo\n",
    "        BestModel = modelo.bestModel\n",
    "\n",
    "        # Resumo de cada modelo\n",
    "        \n",
    "        # Métricas do modelo\n",
    "        if tipo_algo in(\"DecisionTreeRegressor\"):\n",
    "            \n",
    "            # Variável global\n",
    "            global DT_BestModel \n",
    "            DT_BestModel = modelo.bestModel\n",
    "            \n",
    "            # Previsões com dados de teste\n",
    "            previsoes_DT = DT_BestModel.transform(dados_teste)\n",
    "            \n",
    "            print('\\033[1m' + \"Modelo Decision Tree Com Validação Cruzada:\" + '\\033[0m')\n",
    "            print(\" \")\n",
    "            \n",
    "            # Avaliação do modelo\n",
    "            resultado_teste_rmse = eval_rmse.evaluate(previsoes_DT)\n",
    "            print('RMSE em Teste:', resultado_teste_rmse)\n",
    "        \n",
    "            resultado_teste_r2 = eval_r2.evaluate(previsoes_DT)\n",
    "            print('Coeficiente R2 em Teste:', resultado_teste_r2)\n",
    "            print(\"\")\n",
    "        \n",
    "        # Métricas do modelo\n",
    "        if tipo_algo in(\"RandomForestRegressor\"):\n",
    "            \n",
    "            # Variável global\n",
    "            global RF_BestModel \n",
    "            RF_BestModel = modelo.bestModel\n",
    "            \n",
    "            # Previsões com dados de teste\n",
    "            previsoes_RF = RF_BestModel.transform(dados_teste)\n",
    "            \n",
    "            print('\\033[1m' + \"Modelo RandomForest Com Validação Cruzada:\" + '\\033[0m')\n",
    "            print(\" \")\n",
    "            \n",
    "            # Avaliação do modelo\n",
    "            resultado_teste_rmse = eval_rmse.evaluate(previsoes_RF)\n",
    "            print('RMSE em Teste:', resultado_teste_rmse)\n",
    "        \n",
    "            resultado_teste_r2 = eval_r2.evaluate(previsoes_RF)\n",
    "            print('Coeficiente R2 em Teste:', resultado_teste_r2)\n",
    "            print(\"\")\n",
    "        \n",
    "        # Métricas do modelo\n",
    "        if tipo_algo in(\"GBTRegressor\"):\n",
    "\n",
    "            # Variável global\n",
    "            global GBT_BestModel \n",
    "            GBT_BestModel = modelo.bestModel\n",
    "            \n",
    "            # Previsões com dados de teste\n",
    "            previsoes_GBT = GBT_BestModel.transform(dados_teste)\n",
    "            \n",
    "            print('\\033[1m' + \"Modelo Gradient-Boosted Tree (GBT) Com Validação Cruzada:\" + '\\033[0m')\n",
    "            print(\" \")\n",
    "            \n",
    "            # Avaliação do modelo\n",
    "            resultado_teste_rmse = eval_rmse.evaluate(previsoes_GBT)\n",
    "            print('RMSE em Teste:', resultado_teste_rmse)\n",
    "        \n",
    "            resultado_teste_r2 = eval_r2.evaluate(previsoes_GBT)\n",
    "            print('Coeficiente R2 em Teste:', resultado_teste_r2)\n",
    "            print(\"\")\n",
    "            \n",
    "        # Métricas do modelo\n",
    "        if tipo_algo in(\"IsotonicRegression\"):\n",
    "\n",
    "            # Variável global\n",
    "            global ISO_BestModel \n",
    "            ISO_BestModel = modelo.bestModel\n",
    "            \n",
    "            # Previsões com dados de teste\n",
    "            previsoes_ISO = ISO_BestModel.transform(dados_teste)\n",
    "            \n",
    "            print('\\033[1m' + \"Modelo Isotonic Com Validação Cruzada:\" + '\\033[0m')\n",
    "            print(\" \")\n",
    "            \n",
    "            # Avaliação do modelo\n",
    "            resultado_teste_rmse = eval_rmse.evaluate(previsoes_ISO)\n",
    "            print('RMSE em Teste:', resultado_teste_rmse)\n",
    "        \n",
    "            resultado_teste_r2 = eval_r2.evaluate(previsoes_ISO)\n",
    "            print('Coeficiente R2 em Teste:', resultado_teste_r2)\n",
    "            print(\"\")\n",
    "                    \n",
    "        # Lista de colunas para colocar no dataframe de resumo\n",
    "        columns = ['Regressor', 'Resultado_RMSE', 'Resultado_R2']\n",
    "        \n",
    "        # Faz previsões com dados de teste\n",
    "        previsoes = modelo.transform(dados_teste)\n",
    "        \n",
    "        # Avalia o modelo para gravar o resultado\n",
    "        eval_rmse = RegressionEvaluator(metricName = \"rmse\")\n",
    "        rmse = eval_rmse.evaluate(previsoes)\n",
    "        rmse_str = [str(rmse)]\n",
    "        \n",
    "        eval_r2 = RegressionEvaluator(metricName = \"r2\")\n",
    "        r2 = eval_r2.evaluate(previsoes)\n",
    "        r2_str = [str(r2)]\n",
    "         \n",
    "        tipo_algo = [tipo_algo] \n",
    "        \n",
    "        # Cria o dataframe\n",
    "        df_resultado = spark.createDataFrame(zip(tipo_algo, rmse_str, r2_str), schema = columns)\n",
    "        \n",
    "        # Grava o resultado no dataframe\n",
    "        df_resultado = df_resultado.withColumn('Resultado_RMSE', df_resultado.Resultado_RMSE.substr(0, 5))\n",
    "        df_resultado = df_resultado.withColumn('Resultado_R2', df_resultado.Resultado_R2.substr(0, 5))\n",
    "        \n",
    "        return df_resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Agora executamos o módulo de Machine Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de algoritmos\n",
    "regressores = [LinearRegression(),\n",
    "               DecisionTreeRegressor(),\n",
    "               RandomForestRegressor(),\n",
    "               GBTRegressor(),\n",
    "               IsotonicRegression()] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de colunas e valores\n",
    "colunas = ['Regressor', 'Resultado_RMSE', 'Resultado_R2']\n",
    "valores = [(\"N/A\", \"N/A\", \"N/A\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepara a tabela de resumo\n",
    "df_resultados_treinamento = spark.createDataFrame(valores, colunas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mModelo de Regressão Linear Sem Validação Cruzada:\u001b[0m\n",
      "\n",
      "RMSE em Teste: 10.590278315781386\n",
      "Coeficiente R2 em Teste: 0.6373041245240899\n",
      "\n",
      "\u001b[1mModelo de Regressão Linear Com Validação Cruzada:\u001b[0m\n",
      "\n",
      "RMSE em Teste: 10.588466573454399\n",
      "Coeficiente R2 em Teste: 0.6374282110196162\n",
      "\n",
      "\u001b[1mModelo Decision Tree Com Validação Cruzada:\u001b[0m\n",
      " \n",
      "RMSE em Teste: 9.37718077188228\n",
      "Coeficiente R2 em Teste: 0.7156374197479287\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.util.SizeEstimator$ (file:/Users/dmpm/opt/anaconda3/lib/python3.9/site-packages/pyspark/jars/spark-core_2.12-3.3.0.jar) to field java.nio.charset.Charset.name\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.util.SizeEstimator$\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mModelo RandomForest Com Validação Cruzada:\u001b[0m\n",
      " \n",
      "RMSE em Teste: 8.353634783457133\n",
      "Coeficiente R2 em Teste: 0.7743273971320008\n",
      "\n",
      "\u001b[1mModelo Gradient-Boosted Tree (GBT) Com Validação Cruzada:\u001b[0m\n",
      " \n",
      "RMSE em Teste: 7.314219416111147\n",
      "Coeficiente R2 em Teste: 0.8269929350617196\n",
      "\n",
      "\u001b[1mModelo Isotonic Com Validação Cruzada:\u001b[0m\n",
      " \n",
      "RMSE em Teste: 14.86037642252678\n",
      "Coeficiente R2 em Teste: 0.2858532064436079\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loop de treinamento\n",
    "for regressor in regressores:\n",
    "    \n",
    "    # Para cada regressor obtém o resultado\n",
    "    resultado_modelo = func_modulo_ml(regressor)\n",
    "    \n",
    "    # Grava os resultados\n",
    "    df_resultados_treinamento = df_resultados_treinamento.union(resultado_modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retorna as linhas diferentes de N/A\n",
    "df_resultados_treinamento = df_resultados_treinamento.where(\"Regressor!='N/A'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+--------------+------------+\n",
      "|Regressor            |Resultado_RMSE|Resultado_R2|\n",
      "+---------------------+--------------+------------+\n",
      "|LinearRegression     |10.58         |0.637       |\n",
      "|DecisionTreeRegressor|9.377         |0.715       |\n",
      "|RandomForestRegressor|8.353         |0.774       |\n",
      "|GBTRegressor         |7.314         |0.826       |\n",
      "|IsotonicRegression   |14.86         |0.285       |\n",
      "+---------------------+--------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imprime\n",
    "df_resultados_treinamento.show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> O modelo GBT apresentou a melhor performance geral e será usado em produção."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fazendo Previsões com o Modelo Treinado\n",
    "\n",
    "Para fazer as previsões com o modelo treinado, vamos preparar um registro com novos dados.\n",
    "\n",
    "- Cement: 540\n",
    "- Blast Furnace Slag: 0\n",
    "- Fly Ash: 0\n",
    "- Water: 162\n",
    "- Superplasticizer: 2.5\n",
    "- Coarse Aggregate: 1040\n",
    "- Fine Aggregate: 676\n",
    "- Age: 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista dos valores de entrada\n",
    "values = [(540,0.0,0.0,162,2.5,1040,676,28)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nomes das colunas\n",
    "column_names = dados.columns\n",
    "column_names = column_names[0:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Associa valores aos nomes de coluna\n",
    "novos_dados = spark.createDataFrame(values, column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicamos na coluna age a mesma transformação aplicada na preparação dos dados.\n",
    "novos_dados = novos_dados.withColumn(\"age\", log(\"age\") +1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de atributos\n",
    "lista_atributos = [\"cement\",\n",
    "                   \"slag\",\n",
    "                   \"flyash\",\n",
    "                   \"water\",\n",
    "                   \"superplasticizer\",\n",
    "                   \"coarseaggregate\",\n",
    "                   \"fineaggregate\",\n",
    "                   \"age\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o vetorizador\n",
    "assembler = VectorAssembler(inputCols = lista_atributos, outputCol = 'features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforma os dados em vetor\n",
    "novos_dados = assembler.transform(novos_dados).select('features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padroniza os dados (mesma transformação aplicada aos dados de treino)\n",
    "novos_dados_scaled = scalerModel.transform(novos_dados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleciona a coluna resultante\n",
    "novos_dados_final = novos_dados_scaled.select('scaledFeatures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renomeia a coluna (requerimento do MLlib)\n",
    "novos_dados_final = novos_dados_final.withColumnRenamed('scaledFeatures','features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previsões com novos dados usando o modelo de melhor performance\n",
    "previsoes_novos_dados = GBT_BestModel.transform(novos_dados_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|            features|        prediction|\n",
      "+--------------------+------------------+\n",
      "|[1.0,0.0,0.0,0.32...|34.163861234424175|\n",
      "+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Resultado\n",
    "previsoes_novos_dados.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
