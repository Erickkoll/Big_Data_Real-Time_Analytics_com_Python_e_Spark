{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9e32795-efee-4635-ab3b-96a69ac3e973",
   "metadata": {},
   "source": [
    "# <font color='blue'>Data Science Academy</font>\n",
    "# <font color='blue'>Big Data Real-Time Analytics com Python e Spark</font>\n",
    "\n",
    "## <font color='blue'>Mini-Projeto 6</font>\n",
    "\n",
    "### <font color='blue'>Análise de Dados de Sensores IoT em Tempo Real com Apache Spark Streaming e Apache Kafka</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5ccdd6",
   "metadata": {},
   "source": [
    "![title](imagens/MP6.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbafefd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Versão da Linguagem Python\n",
    "from platform import python_version\n",
    "print('Versão da Linguagem Python Usada Neste Jupyter Notebook:', python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de77becb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para atualizar um pacote, execute o comando abaixo no terminal ou prompt de comando:\n",
    "# pip install -U nome_pacote\n",
    "\n",
    "# Para instalar a versão exata de um pacote, execute o comando abaixo no terminal ou prompt de comando:\n",
    "#!pip install nome_pacote==versão_desejada\n",
    "\n",
    "# Depois de instalar ou atualizar o pacote, reinicie o jupyter notebook.\n",
    "\n",
    "# Instala o pacote watermark. \n",
    "# Esse pacote é usado para gravar as versões de outros pacotes usados neste jupyter notebook.\n",
    "#!pip install -q -U watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50a5691",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3183aeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa o findspark e inicializa\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14c6950-525d-4e54-a25e-13e9d6818c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import pyspark\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType\n",
    "from pyspark.sql.functions import col, from_json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29efd4a",
   "metadata": {},
   "source": [
    "> Precisamos incluir o conector de integração do Spark Streaming com o Apache Kafka. Fique atento à versão do PySpark que está sendo usada.\n",
    "\n",
    "https://spark.apache.org/docs/latest/structured-streaming-kafka-integration.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5172de34-9787-4f22-b1a7-8e9bb3b7cbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conector\n",
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.0 pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488dcaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Versões dos pacotes usados neste jupyter notebook\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Data Science Academy\" --iversions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efeedac",
   "metadata": {},
   "source": [
    "## Criando a Sessão Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35f1973-363c-4112-8440-62fca2410984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria a sessão Spark\n",
    "spark = SparkSession.builder.appName(\"Mini-Projeto6\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8744ef",
   "metadata": {},
   "source": [
    "## Leitura do Kafka Spark Structured Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0de89c-e700-4754-9175-d95777b95a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos criar uma subscrição no tópico que tem o streaming de dados que desejamos \"puxar\" os dados.\n",
    "df = spark \\\n",
    "  .readStream \\\n",
    "  .format(\"kafka\") \\\n",
    "  .option(\"kafka.bootstrap.servers\", \"localhost:9092\") \\\n",
    "  .option(\"subscribe\", \"dsamp6\") \\\n",
    "  .load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc60991a",
   "metadata": {},
   "source": [
    "## Definição do Schema da Fonte de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92c2301-7f4c-48fd-8e5a-cc12384ad834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos o schema dos dados que desejamos capturar para análise (temperatura)\n",
    "esquema_dados_temp = StructType([StructField(\"leitura\", \n",
    "                                             StructType([StructField(\"temperatura\", DoubleType(), True)]), True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0a8f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos o schema global dos dados no streaming\n",
    "esquema_dados = StructType([ \n",
    "    StructField(\"id_sensor\", StringType(), True), \n",
    "    StructField(\"id_equipamento\", StringType(), True), \n",
    "    StructField(\"sensor\", StringType(), True), \n",
    "    StructField(\"data_evento\", StringType(), True), \n",
    "    StructField(\"padrao\", esquema_dados_temp, True)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf910ee0",
   "metadata": {},
   "source": [
    "## Parse da Fonte de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a505e1-6004-48ab-8275-0cdb96de583a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capturamos cada linha de dado (cada valor) como string\n",
    "df_conversao = df.selectExpr(\"CAST(value AS STRING)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcc58eb-a9b5-4760-8c09-abe6bdd117b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse do formato JSON em dataframe\n",
    "df_conversao = df_conversao.withColumn(\"jsonData\", from_json(col(\"value\"), esquema_dados)).select(\"jsonData.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77250a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_conversao.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d91c83",
   "metadata": {},
   "source": [
    "## Preparamos o Dataframe \n",
    "\n",
    "Esse dataframe está no formato que precisamos para análise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9734cc6-fd90-4f32-aa7f-dafcf5bc5688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renomeamos as colunas para simplificar nossa análise\n",
    "df_conversao_temp_sensor = df_conversao.select(col(\"padrao.leitura.temperatura\").alias(\"temperatura\"), \n",
    "                                               col(\"sensor\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d725e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_conversao_temp_sensor.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a99b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Não podemos visualizar o dataframe, pois a fonte é de streaming\n",
    "# df_conversao_temp_sensor.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef4ea01",
   "metadata": {},
   "source": [
    "## Análise de Dados em Tempo Real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16da9087-67a4-4f16-8325-7d25dcd8d5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aqui temos o objeto que irá conter nossa análise, o cálculo da média das temperaturas por sensor\n",
    "df_media_temp_sensor = df_conversao_temp_sensor.groupby(\"sensor\").mean(\"temperatura\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c515750",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_media_temp_sensor.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c666eb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renomeamos as colunas para simplificar nossa análise\n",
    "df_media_temp_sensor = df_media_temp_sensor.select(col(\"sensor\").alias(\"sensor\"), \n",
    "                                                   col(\"avg(temperatura)\").alias(\"media_temp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dedc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_media_temp_sensor.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fe8621",
   "metadata": {},
   "source": [
    "Abaixo abrimos o streaming para análise de dados em tempo real, imprimindo o resultado no console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3946d80-165e-47a5-a921-56e3d6e675d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objeto que inicia a consulta ao streaming com formato de console\n",
    "query = df_media_temp_sensor.writeStream.outputMode(\"complete\").format(\"console\").start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e8a6d2",
   "metadata": {},
   "source": [
    "Envie novos arquivos para o Kafka a fim de ver a análise em tempo real por aqui. Clique no botão Stop no menu superior para interromper a célula a qualquer momento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5792c3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executamos a query do streaming e evitamos que o processo seja encerrado\n",
    "query.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41028bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "query.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae4ad89",
   "metadata": {},
   "outputs": [],
   "source": [
    "query.lastProgress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4e69b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "query.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e469f93",
   "metadata": {},
   "source": [
    "## Análise de Dados em Tempo Real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65867a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objeto que inicia a consulta ao streaming com formato de memória (cria tabela temporária)\n",
    "query_memoria = df_media_temp_sensor \\\n",
    "    .writeStream \\\n",
    "    .queryName(\"dsa\") \\\n",
    "    .outputMode(\"complete\") \\\n",
    "    .format(\"memory\") \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706168fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streams ativados\n",
    "spark.streams.active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac82b405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos manter a query executando por algum tempo e aplicando SQL aos dados em tempo real\n",
    "from time import sleep\n",
    "\n",
    "for x in range(10):\n",
    "    \n",
    "    spark.sql(\"select sensor, round(media_temp, 2) as media from dsa where media_temp > 65\").show()\n",
    "    sleep(3)\n",
    "    \n",
    "query_memoria.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36441eef",
   "metadata": {},
   "source": [
    "# Fim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
